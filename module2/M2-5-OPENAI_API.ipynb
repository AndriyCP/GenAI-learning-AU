{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1af6eb-2b2c-4c61-8c7a-215ee1e1f1e8",
   "metadata": {},
   "source": [
    "## Calling OpenAI's GPT using a REST API\n",
    "For students learning about AI, leveraging GPT model through a REST API can be a valuable way to explore and integrate advanced natural language processing capabilities into their applications. The GPT models are accessible through a well-documented REST API that allows developers to send text prompts and receive responses generated by the powerful language model. By understanding how to interact with this type of AI-powered REST API, students can expand the functionality of their projects, experiment with different use cases, and gain practical experience in incorporating state-of-the-art AI technologies into real-world applications.\n",
    "### Table of Contents\n",
    "1. [Setup your OpenAI API key](#setup)\n",
    "2. [Make a simple API call to one of OpenAI's models](#simple)\n",
    "3. [A few options for using the API](#options)\n",
    "4. [Your assignment](#assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b669b4-fb42-47cb-af5f-f6f47f2cbf70",
   "metadata": {},
   "source": [
    "## Setup your OpenAI API key<a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f7f885-9ee2-4810-95ff-9c6f85da456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# This package is not installed in our Sagemaker image.\n",
    "# Everytime you researt this jupyterlab, you will have to reinstall it.\n",
    "%pip install python-dotenv\n",
    "# Now import the objects we need\n",
    "from dotenv import load_dotenv\n",
    "# Other needed packages to import\n",
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30712831-2b1a-46ca-b4f5-c63aea7d8c12",
   "metadata": {},
   "source": [
    "To store your API key for use with the requests package:\n",
    "- Get the key from your account on https://platform.openai.com/settings/profile?tab=api-keys. It will look something like: \"sk-ant-api03-Iu4 ... U37M\"\n",
    "- Now, open a terminal from the jupyter Launcher\n",
    "    - Use the nano text editor (or any other editor)\n",
    "    - Create a .env file (that is a file with the exact name \".env\" (files that start with '.' are hidden by default\n",
    "    - Add a line that looks like this: OPENAI_API_KEY=\"your_key\"\n",
    "       - Insert your key in double-quotes\n",
    "    - Save the file and exit the text editor. In nano: Save (ctl-o), Exit (ctl-x)\n",
    "\n",
    "<P>\n",
    "Next we will load this key into this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce74efc3-5f13-4486-b4fb-9fae3fe55e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Now you can access the environment variable\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# You can print the key to make sure it is there, but I get nervous when I see a key printed somewhere.... Someone could steal it!\n",
    "#print(openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc85cf-7502-4afd-80b2-d7d391a692c0",
   "metadata": {},
   "source": [
    "## Make a simple API call to one of OpenAI's models<a name=\"simple\"></a>\n",
    " - If you want to know more: https://platform.openai.com/docs/quickstart\n",
    " - API Reference: https://platform.openai.com/docs/api-reference/chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38deb48e-c33d-4346-9ed8-b10700de087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API endpoint\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "# Set the request headers\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {openai_api_key}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa8dba5-94de-49a4-9f66-90be53d04288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo\", # models: https://platform.openai.com/docs/models/overview\n",
    "        'max_tokens': 1024,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\"content\": \"Write a blog post about large language models.\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c31299-abcb-4dee-9ca6-51e54f3d6304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Make the API POST request.\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable\n",
    "    generated_text = response.json()['choices'][0]['message']['content']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "#\n",
    "# When you execute this cell, you are paying to inference the model. It will deduct money from your account.\n",
    "# Therefore, I usually do anything in this cell other than store the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a43b64-72e8-4872-b655-7e64a59d95fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models, such as GPT-3 (Generative Pre-trained Transformer 3), have been making waves in the field of natural language processing in recent years. These models have the ability to generate human-like text and can be used for a wide range of tasks, from language translation to text generation to question answering.\n",
      "\n",
      "One of the main advantages of large language models is their ability to generate coherent and contextually relevant text. These models have been trained on vast amounts of text data, allowing them to understand the nuances of language and generate text that is highly accurate and fluent. This makes them incredibly valuable for tasks such as content creation, where the ability to generate high-quality text quickly is essential.\n",
      "\n",
      "Large language models also have the potential to transform the way we interact with technology. For example, they can be used to power chatbots and virtual assistants that can engage in natural and intelligent conversations with users. This has the potential to revolutionize customer service and make interactions with technology more seamless and intuitive.\n",
      "\n",
      "However, large language models are not without their limitations. One of the main concerns with these models is their potential to perpetuate biases present in the text data they were trained on. If the training data contains biased or problematic language, the model may learn and reproduce these biases in its output. This raises important ethical considerations around the use of large language models and the importance of ensuring that they are used in a responsible and ethical manner.\n",
      "\n",
      "Despite these concerns, large language models have the potential to have a transformative impact on a wide range of industries and applications. As researchers continue to push the boundaries of what these models can do, we can expect to see even more impressive applications in the future. Whether it's improving content creation, enhancing virtual assistants, or enabling new forms of human-computer interaction, large language models are set to shape the future of natural language processing in exciting and innovative ways.\n"
     ]
    }
   ],
   "source": [
    "# Look at the resposne\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395cf782-805a-4bcc-96fa-83a31bf8d5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9EjnUFX6so1rxgQoletaqUDkHx7nt',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1713299664,\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': \"Large language models, such as GPT-3 (Generative Pre-trained Transformer 3), have been making waves in the field of natural language processing in recent years. These models have the ability to generate human-like text and can be used for a wide range of tasks, from language translation to text generation to question answering.\\n\\nOne of the main advantages of large language models is their ability to generate coherent and contextually relevant text. These models have been trained on vast amounts of text data, allowing them to understand the nuances of language and generate text that is highly accurate and fluent. This makes them incredibly valuable for tasks such as content creation, where the ability to generate high-quality text quickly is essential.\\n\\nLarge language models also have the potential to transform the way we interact with technology. For example, they can be used to power chatbots and virtual assistants that can engage in natural and intelligent conversations with users. This has the potential to revolutionize customer service and make interactions with technology more seamless and intuitive.\\n\\nHowever, large language models are not without their limitations. One of the main concerns with these models is their potential to perpetuate biases present in the text data they were trained on. If the training data contains biased or problematic language, the model may learn and reproduce these biases in its output. This raises important ethical considerations around the use of large language models and the importance of ensuring that they are used in a responsible and ethical manner.\\n\\nDespite these concerns, large language models have the potential to have a transformative impact on a wide range of industries and applications. As researchers continue to push the boundaries of what these models can do, we can expect to see even more impressive applications in the future. Whether it's improving content creation, enhancing virtual assistants, or enabling new forms of human-computer interaction, large language models are set to shape the future of natural language processing in exciting and innovative ways.\"},\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 16, 'completion_tokens': 377, 'total_tokens': 393},\n",
       " 'system_fingerprint': 'fp_c2295e73ad'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look closer at the entire response. Other data is included\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f9c82-19f8-4603-a913-83b436f0dfbc",
   "metadata": {},
   "source": [
    "## A few options for using the API<a name=\"options\"></a>\n",
    "- max_tokens\n",
    "- temperature\n",
    "- Multiple conversational turns\n",
    "- Using the conversation history in multiple API calls (keeping the context of the conversation active)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b87d21-af97-40c5-ac0d-8f5ef627322e",
   "metadata": {},
   "source": [
    "#### max_tokens\n",
    "When using the OpenAI API, the `max_tokens` parameter is an important setting that allows you to control the length of the generated text response. The `max_tokens` parameter specifies the maximum number of tokens (words or word pieces) that the model should generate in the response. This is useful for preventing the model from generating excessively long or open-ended responses, which can help manage the response size and cost when using the API. By adjusting the `max_tokens` value, you can balance the desired level of detail and conciseness in the generated text to best fit the needs of your application. Understanding how to effectively leverage the `max_tokens` parameter is an important consideration when integrating the powerful OpenAI language model through the REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b280fc6-2bbd-417b-8b0c-61c9597b5aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Max tokens\n",
    "# Define the data\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo\", # models: https://platform.openai.com/docs/models/overview\n",
    "    \"max_tokens\": 100,\n",
    "    \"messages\": [\n",
    "        # {\n",
    "        #     \"role\": \"system\",\n",
    "        #     \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"\n",
    "        # },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a blog post about large language models.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable\n",
    "    generated_text = response.json()['choices'][0]['message']['content']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1530d0b-ae3e-487f-996e-a6c37974b375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language models have come a long way in recent years, with the advent of large transformer-based models such as GPT-3, developed by OpenAI. These models are capable of generating human-like text and have the potential to revolutionize various aspects of communication, content creation, and even decision-making.\n",
      "\n",
      "One of the key advantages of large language models is their ability to understand and generate complex and nuanced text. This makes them incredibly useful for a wide range of applications, from writing news articles and marketing copy\n",
      "\n",
      "\n",
      "Why the response ended: length\n",
      "Token usage: {'prompt_tokens': 16, 'completion_tokens': 100, 'total_tokens': 116}\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)\n",
    "# Let's look at a few fields in the response\n",
    "print('\\n\\nWhy the response ended:', response.json()['choices'][0]['finish_reason'])\n",
    "print('Token usage:', response.json()['usage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ff4e2-8311-4888-b256-b27f605ddc95",
   "metadata": {},
   "source": [
    "#### temperature\n",
    "The `temperature` parameter in the API is a setting that controls the \"creativity\" or \"randomness\" of the generated text. In the OpenAI API, temperature is a value between 0 and 2 that affects the model's probability distribution when choosing the next token in the output. \n",
    "\n",
    "A lower temperature (closer to 0) results in more deterministic, logical, and \"safer\" text generation, as the model will tend to choose the most probable next tokens based on the training data. This can be useful for generating text that needs to adhere to specific guidelines or patterns.\n",
    "\n",
    "Conversely, a higher temperature (closer to 2) introduces more randomness and creativity into the text generation process. The model will explore a wider range of possible next tokens, leading to more diverse, unexpected, and imaginative outputs. This can be beneficial for tasks like creative writing, brainstorming, or open-ended exploration.\n",
    "\n",
    "By adjusting the `temperature` parameter, users of the API can control the balance between coherence/safety and creativity/unpredictability in the model's generated text, allowing them to fine-tune the output to best suit their specific application needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b2455c-f55f-4a51-894b-d3f7d81f3e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Temperature (low temperature, less random, more deterministic or conservative)\n",
    "# Define the data\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo\", # models: https://platform.openai.com/docs/models/overview\n",
    "    # Low temperature (more deterministic, less random and creative)\n",
    "    'temperature':0,\n",
    "    \"max_tokens\": 100,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please tell me a bedtime story.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable    \n",
    "    generated_text = response.json()['choices'][0]['message']['content']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35865295-aec5-4237-9eab-d824cff84cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a faraway land, there was a magical forest where all the animals lived in harmony. The forest was ruled by a wise old owl named Ollie, who was known for his wisdom and kindness.\n",
      "\n",
      "One day, a young fox named Finn wandered into the forest, lost and scared. He had been separated from his family and didn't know how to find his way back home. Ollie took pity on the young fox and offered to help him.\n",
      "\n",
      "Together,\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd883f96-e3be-4a0f-b6ff-16f31d8519f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Temperature (High temperature, more random and creative)\n",
    "# Define the data\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo\", # models: https://platform.openai.com/docs/models/overview\n",
    "    # High temperature\n",
    "    'temperature':2.0,\n",
    "    \"max_tokens\": 100,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Please tell me a bedtime story.\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable        \n",
    "    generated_text = response.json()['choices'][0]['message']['content']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267d66c0-63c0-4a95-94cf-a80151d81be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a mystical kingdom, there lived a young princess named Aurora. Aurora was known throughout the land for her kindness, beauty, and adventurous spirit.\n",
      "\n",
      "One day, while exploring the palace grounds, Aurora stumbled upon found a map tucked away in the back of a dusty book. The map showed hidden symbols leading to an enchanted garden filled with the rarest and most exquisite flowers in the realm.\n",
      "\n",
      "Determined to uncover the mysteries of the enchanted garden, Aurora set off into the forest,\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc317e-959f-46eb-b8fe-518563b611cc",
   "metadata": {},
   "source": [
    "#### multiple conversation turns\n",
    "When using the OpenAI API, the ability to maintain multiple conversation turns is an important feature. This allows you to provide the model with a conversational context, where each subsequent request builds upon the previous responses. The API supports storing this conversational state, enabling the model to understand and respond to the evolving context. This can be particularly useful for creating more natural, coherent, and contextual interactions between the user and the AI assistant. By leveraging multiple conversation turns, you can create more engaging and informative dialogues that draw upon the model's accumulated knowledge and understanding of the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0c7408b-3e24-4959-8260-c8ad7c6e47ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Multiple conversational turns:\n",
    "# Define the data\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo\", # models: https://platform.openai.com/docs/models/overview\n",
    "    \"max_tokens\": 500,\n",
    "    \"messages\": [\n",
    "          {\"role\": \"user\", \"content\": \"I have an AI question, are you ready?\"},\n",
    "          {\"role\": \"assistant\", \"content\": \"Hi, I'm GPT, an AI assistant, so I know a lot about it. Please, please ask me anything about AI.\"},\n",
    "          {\"role\": \"user\", \"content\": \"Can you explain Artificial Neural Networks plain English, including an analogy?\"}\n",
    "    ]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable       \n",
    "    generated_text = response.json()['choices'][0]['message']['content']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "691492f3-55f1-409a-9c75-2f359e36f4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! Artificial Neural Networks (ANNs) are a type of machine learning algorithm inspired by the way the human brain works. \n",
      "\n",
      "Imagine your brain as a network of interconnected neurons, each one responsible for processing and transmitting information. In a similar way, an Artificial Neural Network consists of interconnected nodes called artificial neurons or units. These artificial neurons receive input data, process it through a series of mathematical operations, and produce an output. \n",
      "\n",
      "Here's an analogy: Think of an Artificial Neural Network as a team of workers in a factory. Each worker (neuron) has a specific role and processes a specific piece of information. They communicate with each other to make decisions and solve problems, just like neurons in the brain work together to process information and make decisions.\n",
      "\n",
      "Overall, Artificial Neural Networks are powerful tools for tasks like pattern recognition, classification, and prediction, and they can learn from data to improve their performance over time.\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a54f9-6312-4bab-86a6-7f0f5f3c92b3",
   "metadata": {},
   "source": [
    "#### Using the conversation history in multiple API calls\n",
    "The OpenAI API supports the ability to maintain and utilize conversation history across multiple API calls. By passing the conversation history as part of each subsequent request, the model can reference and build upon the prior context, resulting in more coherent and contextual responses. Leveraging the conversation history is particularly useful for tasks that require an ongoing dialogue, such as open-ended Q&A, task completion, or collaborative ideation. This feature allows you to create more natural and engaging interactions, where the AI assistant can demonstrate an understanding of the discussion and provide relevant and tailored responses based on the evolving conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e976f122-2be0-4111-a0b3-5d5010c20a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to keep the API text responses\n",
    "message_lst = [] #empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7df1c1e6-a67b-4eec-afa2-a45589ba3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Define the data\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo\", # models: https://platform.openai.com/docs/models/overview\n",
    "    \"max_tokens\": 500,\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"Please explain the difference between Artifical Intelligence and Machine Learning.\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable           \n",
    "    generated_text = response.json()['choices'][0]['message']['content']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "# Keep a history: append the text to the list\n",
    "message_lst.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d87752b-dc9b-4ce9-bb33-32b446007e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry: 1 \n",
      " Text: Artificial Intelligence (AI) and Machine Learning (ML) are related concepts, but they are not the same thing.\n",
      "\n",
      "Artificial Intelligence is a broad field of study that aims to create machines that can perform tasks that typically require human intelligence, such as speech recognition, decision-making, and problem-solving. AI can be further divided into two categories: narrow AI and general AI. Narrow AI refers to AI systems that are designed for specific tasks, while general AI aims to develop machines that can perform any intellectual task that a human can.\n",
      "\n",
      "Machine Learning, on the other hand, is a specific subset of AI that focuses on developing algorithms and statistical models that allow machines to learn from and make predictions or decisions based on data. In other words, machine learning is a method that enables AI systems to improve their performance over time without being explicitly programmed. \n",
      "\n",
      "In summary, AI is the broader field encompassing the development of intelligent machines, while machine learning is a specific technique within AI that focuses on enabling machines to learn from data and improve their performance. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at our current list of responses\n",
    "for i,r in enumerate(message_lst):\n",
    "    print('Entry:', i+1, '\\n','Text:', r,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b0080f0-2a4a-4b10-823e-bd4832146e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Pass the history back into the assistant with a follow-up instruction.\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo\", # models: https://platform.openai.com/docs/models/overview\n",
    "    \"max_tokens\": 500,\n",
    "    'messages': [\n",
    "        {\"role\": \"user\", \"content\": \"Please explain the difference between Artifical Intelligence and Machine Learning.\"},\n",
    "        # Pass in the history\n",
    "        {\"role\": \"assistant\", \"content\": \" \".join(message_lst)}, # Combine all messages into a single string\n",
    "        # Give further instructions\n",
    "        {\"role\": \"user\", \"content\": \"Please reduce this explaination to a single paragraph.\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200:\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable            \n",
    "    generated_text = response.json()['choices'][0]['message']['content']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "# Append to the end of the list\n",
    "message_lst.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00654edd-7846-4caf-8437-f4d12f585428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry: 1 \n",
      " Text: Artificial Intelligence (AI) and Machine Learning (ML) are related concepts, but they are not the same thing.\n",
      "\n",
      "Artificial Intelligence is a broad field of study that aims to create machines that can perform tasks that typically require human intelligence, such as speech recognition, decision-making, and problem-solving. AI can be further divided into two categories: narrow AI and general AI. Narrow AI refers to AI systems that are designed for specific tasks, while general AI aims to develop machines that can perform any intellectual task that a human can.\n",
      "\n",
      "Machine Learning, on the other hand, is a specific subset of AI that focuses on developing algorithms and statistical models that allow machines to learn from and make predictions or decisions based on data. In other words, machine learning is a method that enables AI systems to improve their performance over time without being explicitly programmed. \n",
      "\n",
      "In summary, AI is the broader field encompassing the development of intelligent machines, while machine learning is a specific technique within AI that focuses on enabling machines to learn from data and improve their performance. \n",
      "\n",
      "\n",
      "Entry: 2 \n",
      " Text: Artificial Intelligence (AI) is the broader field focused on creating machines capable of human-like tasks, while Machine Learning (ML) is a specific subset of AI that involves developing algorithms for machines to learn from data and make predictions or decisions without explicit programming. In essence, AI aims to make machines intelligent, while ML is a method within AI that enables machines to learn and improve their performance over time. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at our current list of responses\n",
    "for i,r in enumerate(message_lst):\n",
    "    print('Entry:', i+1, '\\n','Text:', r,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2cb0d-e29d-4a7c-a143-427b7f09ab3e",
   "metadata": {},
   "source": [
    "## Your assignment:<a name=\"assignment\"></a>\n",
    "Using the examples above, create 3 unique API calls (different than my examples) using a combination of parameters and techniques. Print your resopnses just as I have done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46160187-bac0-4a3c-971f-f22ba4166862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4da9dd-37e4-4829-9dbe-2615b0e0859b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
