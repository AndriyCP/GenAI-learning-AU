{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72bd44ff-2831-405d-84db-a0f3499e7010",
   "metadata": {},
   "source": [
    "## Introduction to Chains using the LangChain Package\n",
    "\n",
    "LangChain is a powerful open-source Python framework that simplifies the development of applications powered by LLMs. It provides a standard interface and a rich set of features to help developers and researchers create, experiment with, and analyze language models and agents.\n",
    "\n",
    "https://www.langchain.com/\n",
    "\n",
    "The concept of an \"chain\" is an important tool for understanding and building generative AI applications. Chains are a key concept in LangChain, as they allow developers to create complex workflows by chaining together various components, such as language models, data sources, and processing steps.\n",
    "\n",
    "### Table of Contents <a name=\"top\"></a>\n",
    "1. [Create a LLM inside of LangChain](#llm)\n",
    "2. [Prompt Templates](#template)\n",
    "3. [How to chain 2 tasks together](#2chain)\n",
    "4. [Output Parser](#parser)\n",
    "5. [How to chain 3 tasks together](#3chain)\n",
    "\n",
    "This content was adapted from: https://python.langchain.com/docs/get_started/quickstart/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4210ac-3577-443e-8bb0-28183a803d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, in order to run this notebook, you have to run the notebook M2-8a-Config_SM_image to configure the \n",
    "# SageMaker Docker image everytime you stop and restart the Jupyterlab Space.\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c5dce8-037b-4eeb-9736-5b8e40ad41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your API keys\n",
    "#\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Now you can access the environment variables\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "#\n",
    "# Not needed for this notebook\n",
    "# langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "# openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY'\n",
    "# You can always just assign your variable directly, just not good practice to expose your key in a notebook\n",
    "# anthropic_api_key='sk-ant-api03....._AAA' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e4d4c8-d272-4887-b98e-a1f54da1568c",
   "metadata": {},
   "source": [
    "## Create a LLM model inside LangChain <a name=\"llm\"></a>\n",
    "Let's start with creating a chat model. We can use one from a wide selection, some of which will be familiar to you.\n",
    "\n",
    "https://python.langchain.com/docs/integrations/chat/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b441f0e-554e-4a2c-b896-daff1ef7ed08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'claude-3-sonnet-20240229',\n",
       " 'max_tokens': 1024,\n",
       " 'temperature': None,\n",
       " 'top_k': None,\n",
       " 'top_p': None,\n",
       " 'model_kwargs': {},\n",
       " 'streaming': False,\n",
       " 'max_retries': 2,\n",
       " 'default_request_timeout': None,\n",
       " '_type': 'anthropic-chat'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Docs: https://api.python.langchain.com/en/latest/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "claude_llm = ChatAnthropic(model=\"claude-3-sonnet-20240229\",\n",
    "                           api_key=anthropic_api_key\n",
    "                          )\n",
    "# Show some details about the model\n",
    "claude_llm.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e7918-afb0-4015-8f64-35bef1aacf03",
   "metadata": {},
   "source": [
    "#### Many other chat models are possible in LangChain\n",
    "OpenAI Chat Model: https: https://python.langchain.com/docs/integrations/platforms/openai/<BR>\n",
    "HuggingFace Chat Model: https://python.langchain.com/docs/integrations/chat/huggingface/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a87ba9e9-4a9e-4af2-9625-6b773dcef4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple prompt using a string\n",
    "raw_input = \"Who is Socrates and why is he relevant to effective teaching?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa273440-134c-4cb9-b7f9-e5e75450964d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the type of response?: <class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "# Invoke the model with our prompt (This uses your API KEY to call the model)\n",
    "response = claude_llm.invoke(raw_input, max_tokens = 1024)\n",
    "#\n",
    "# The output from the LLM is an object called AIMessage\n",
    "print(\"What is the type of response?:\", type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d40477c-8003-492f-a4b8-501977219dec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Socrates (470-399 BC) was an ancient Greek philosopher who is considered one of the founders of Western philosophy. He is highly relevant to effective teaching for several reasons:\\n\\n1. The Socratic Method: Socrates developed a teaching method based on asking thought-provoking questions to stimulate critical thinking and draw out ideas from his students. This method, known as the Socratic method, encourages active learning through dialogue and questioning rather than passive reception of information.\\n\\n2. Emphasis on Questioning: Socrates believed that questioning was central to learning and understanding. By asking probing questions, he challenged his students to examine their assumptions, justify their beliefs, and arrive at their own conclusions through reason and logic.\\n\\n3. Focus on Conceptual Understanding: Instead of merely transmitting factual information, Socrates aimed to develop a deeper conceptual understanding in his students. He wanted them to grasp the underlying principles and reasoning behind ideas, rather than simply memorizing facts.\\n\\n4. Intellectual Humility: Socrates famously claimed that he was aware of his own ignorance, which fostered intellectual humility. This attitude encouraged his students to be open-minded, to question their own knowledge, and to engage in continuous learning and self-examination.\\n\\n5. Ethical and Moral Inquiry: Socrates was deeply interested in ethical and moral questions, encouraging his students to examine the nature of virtue, justice, and the good life. This approach to teaching emphasized the development of critical thinking skills and the ability to engage in philosophical discourse.\\n\\nThe Socratic method and Socrates' emphasis on questioning, conceptual understanding, intellectual humility, and ethical inquiry have had a lasting influence on educational practices. Many modern teaching approaches, such as inquiry-based learning, problem-based learning, and discussion-based seminars, draw inspiration from Socratic principles. By fostering critical thinking, active engagement, and a willingness to question assumptions, Socrates' legacy continues to shape effective teaching practices in various disciplines.\", response_metadata={'id': 'msg_01MKKGpX62AxocrtjiFxRgUj', 'model': 'claude-3-sonnet-20240229', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 21, 'output_tokens': 430}}, id='run-06e0586a-33d6-4aca-9302-67fc0059b251-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is the documentation:\n",
    "# https://api.python.langchain.com/en/latest/messages/langchain_core.messages.ai.AIMessage.html\n",
    "#\n",
    "# Just dump the AIMessage to the screen and notice is is more than just text\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "030fdef6-295d-40fa-98e8-b7b4a906e8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"Socrates (470-399 BC) was an ancient Greek philosopher who is considered one of the founders of Western philosophy. He is highly relevant to effective teaching for several reasons:\\n\\n1. The Socratic Method: Socrates developed a teaching method based on asking thought-provoking questions to stimulate critical thinking and draw out ideas from his students. This method, known as the Socratic method, encourages active learning through dialogue and questioning rather than passive reception of information.\\n\\n2. Emphasis on Questioning: Socrates believed that questioning was central to learning and understanding. By asking probing questions, he challenged his students to examine their assumptions, justify their beliefs, and arrive at their own conclusions through reason and logic.\\n\\n3. Focus on Conceptual Understanding: Instead of merely transmitting factual information, Socrates aimed to develop a deeper conceptual understanding in his students. He wanted them to grasp the underlying principles and reasoning behind ideas, rather than simply memorizing facts.\\n\\n4. Intellectual Humility: Socrates famously claimed that he was aware of his own ignorance, which fostered intellectual humility. This attitude encouraged his students to be open-minded, to question their own knowledge, and to engage in continuous learning and self-examination.\\n\\n5. Ethical and Moral Inquiry: Socrates was deeply interested in ethical and moral questions, encouraging his students to examine the nature of virtue, justice, and the good life. This approach to teaching emphasized the development of critical thinking skills and the ability to engage in philosophical discourse.\\n\\nThe Socratic method and Socrates' emphasis on questioning, conceptual understanding, intellectual humility, and ethical inquiry have had a lasting influence on educational practices. Many modern teaching approaches, such as inquiry-based learning, problem-based learning, and discussion-based seminars, draw inspiration from Socratic principles. By fostering critical thinking, active engagement, and a willingness to question assumptions, Socrates' legacy continues to shape effective teaching practices in various disciplines.\",\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'id': 'msg_01MKKGpX62AxocrtjiFxRgUj',\n",
       "  'model': 'claude-3-sonnet-20240229',\n",
       "  'stop_reason': 'end_turn',\n",
       "  'stop_sequence': None,\n",
       "  'usage': {'input_tokens': 21, 'output_tokens': 430}},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-06e0586a-33d6-4aca-9302-67fc0059b251-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also get a Python dictionary\n",
    "response.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87bcf70f-ac25-40ec-af54-f779eb82c9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socrates (470-399 BC) was an ancient Greek philosopher who is considered one of the founders of Western philosophy. He is highly relevant to effective teaching for several reasons:\n",
      "\n",
      "1. The Socratic Method: Socrates developed a teaching method based on asking thought-provoking questions to stimulate critical thinking and draw out ideas from his students. This method, known as the Socratic method, encourages active learning through dialogue and questioning rather than passive reception of information.\n",
      "\n",
      "2. Emphasis on Questioning: Socrates believed that questioning was central to learning and understanding. By asking probing questions, he challenged his students to examine their assumptions, justify their beliefs, and arrive at their own conclusions through reason and logic.\n",
      "\n",
      "3. Focus on Conceptual Understanding: Instead of merely transmitting factual information, Socrates aimed to develop a deeper conceptual understanding in his students. He wanted them to grasp the underlying principles and reasoning behind ideas, rather than simply memorizing facts.\n",
      "\n",
      "4. Intellectual Humility: Socrates famously claimed that he was aware of his own ignorance, which fostered intellectual humility. This attitude encouraged his students to be open-minded, to question their own knowledge, and to engage in continuous learning and self-examination.\n",
      "\n",
      "5. Ethical and Moral Inquiry: Socrates was deeply interested in ethical and moral questions, encouraging his students to examine the nature of virtue, justice, and the good life. This approach to teaching emphasized the development of critical thinking skills and the ability to engage in philosophical discourse.\n",
      "\n",
      "The Socratic method and Socrates' emphasis on questioning, conceptual understanding, intellectual humility, and ethical inquiry have had a lasting influence on educational practices. Many modern teaching approaches, such as inquiry-based learning, problem-based learning, and discussion-based seminars, draw inspiration from Socratic principles. By fostering critical thinking, active engagement, and a willingness to question assumptions, Socrates' legacy continues to shape effective teaching practices in various disciplines.\n"
     ]
    }
   ],
   "source": [
    "# Let's extract just the text using the .content property:\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1e6d3-1774-494d-ab68-2c09789a164e",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "## Prompt Templates <a name=\"template\"></a>\n",
    "We have a model ready to use. Next, let's learn about a prompt template.\n",
    "\n",
    "Prompt templates are predefined recipes for generating prompts for language models. A template may include instructions, few-shot examples, and specific context and questions appropriate for a given task. LangChain provides tooling to create and work with prompt templates. \n",
    "LangChain strives to create model agnostic templates to make it easy to reuse existing templates across different language models. Typically, language models expect the prompt to either be a string or else a list of chat messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6566fdb9-a916-4a56-a754-b14f67ab9367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptInput(adjective=None, topic=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create the prompt object\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"adjective\",\"topic\"],\n",
    "    template=\"What is a {adjective} joke about {topic}?\",\n",
    ")\n",
    "# Check out the prompt schema (or configuration)\n",
    "template.input_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25e024ac-b743-479c-976f-10961680d220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a funny joke about dogs?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use this template by passing the parameters\n",
    "template.format(adjective=\"funny\",topic=\"dogs\") # Pass paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e30468-6fed-46d2-b8a0-89a4b50394c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='What is a strange joke about bears?')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But we can also use the invoke() method and pass a dictionary. \n",
    "# This is much more common, use a dictionary to pass the arguments\n",
    "template.invoke({\"adjective\":\"strange\",\"topic\": \"bears\"}) # Dictionary instead of paramters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dcf3a6-f157-4310-9d3d-ef0ae99942cd",
   "metadata": {},
   "source": [
    "A prompt template is a way to create consistent prompts, leverage variable passing in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267f784-73a0-4d3b-99c8-0e8567c04daa",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "## Chains: How to chain 2 tasks together <a name=\"2chain\"></a>\n",
    "A LangChain **chain** is a fundamental concept in the LangChain framework that allows developers to create  workflows by chaining together various components in to processing steps.\n",
    "\n",
    "In LangChain, a chain refers to a sequence of steps or components that work together to accomplish a specific task. These components can include:\n",
    "\n",
    "1. Language Models (LLMs): The main AI models that generate text, such as GPT-3, Cohere, or Hugging Face models.\n",
    "2. Prompts: The input prompts that are fed into the LLMs to generate the desired output.\n",
    "3. Parsers: Component that convert the format of an output into another format.\n",
    "4. Memory: Components that store and retrieve relevant information to maintain context across multiple steps.\n",
    "5. Agents: Intelligent agents that can dynamically select and use the appropriate tools (e.g., search engines, calculators) to solve a given task.\n",
    "6. Tools: External components that can be integrated into the chain, such as APIs, databases, or other services.\n",
    "\n",
    "Chains allow you to go beyond just a single API call to a language model and instead chain together multiple calls in a logical sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef775e3-b422-4081-98ee-5ab4b45a3232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_anthropic.chat_models.ChatAnthropic'>\n",
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n"
     ]
    }
   ],
   "source": [
    "# So far, we have two LangChain objects:\n",
    "print(type(claude_llm))\n",
    "print(type(template))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17fd5248-7cb2-4d52-a7bc-c5a8c107843c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a chain by linking the two objects in sequence.\n",
    "# Discuss the '|' character\n",
    "chain = template | claude_llm \n",
    "type(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "916eaf70-3883-400f-82c3-89124b5b0cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a happy, silly joke about pumpkins:\n",
      "\n",
      "Why did the pumpkin cross the road? To get to the other side for the harvest festival!\n"
     ]
    }
   ],
   "source": [
    "# To use the chain, use the invoke() method\n",
    "# Define an adjective and topic\n",
    "adj = \"happy\"\n",
    "top = \"pumpkins\"\n",
    "#\n",
    "# We start the chain by using the invoke() method and passing a dictionary\n",
    "#\n",
    "response = chain.invoke({\"adjective\":adj,\"topic\": top})\n",
    "# This output is a combination of both the prompt template and the LLM inferencing the prompt\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5315b02a-920c-4bb0-9076-129a0394d980",
   "metadata": {},
   "source": [
    "So far, we have used a 2-step chain.  Let's work towards a 3-step chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb468b46-a0d9-41b7-b1de-ed9e31cf02c4",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "## Third LangChain Object: Parser <a name=\"parser\"></a>\n",
    "Output parsers are responsible for taking the output of an LLM and transforming it to a more suitable format. This is very useful when you are using LLMs to generate any form of structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "492bb4a1-02f9-46d8-bbdd-d6de8f3d096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# This parser takes the AIMessage reutrned form the LLM and converts it to a string\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ed8a725-4359-4a92-9b61-30b5e9d2cfec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check out the type of the return from the LLM: <class 'langchain_core.messages.ai.AIMessage'> \n",
      "\n",
      "After the parser, the output is of type: <class 'str'> \n",
      "\n",
      "Here's a silly joke for you:\n",
      "\n",
      "Why can't a bicycle stand up by itself?\n",
      "Because it's two-tired!\n"
     ]
    }
   ],
   "source": [
    "# Mannually Invoke the LLM to get a response.\n",
    "response = claude_llm.invoke(\"Tell me a funny joke.\", max_tokens=100)\n",
    "#\n",
    "# Check the type of the response: AIMessage\n",
    "print('Check out the type of the return from the LLM:', type(response), '\\n')\n",
    "#\n",
    "# Let's use the output_parser to convert the AIMessage to a string\n",
    "parsed_response = output_parser.invoke(response)\n",
    "#\n",
    "# Check the type, it should be a string\n",
    "print('After the parser, the output is of type:', type(parsed_response), '\\n')\n",
    "#\n",
    "# Print the string\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc883482-174b-4bb0-8ac8-8663a171ce46",
   "metadata": {},
   "source": [
    "[Top of Page](#top)\n",
    "## Chains: How to chain 3 tasks together  <a name=\"3chain\"></a>\n",
    "Now we have 3 objects: A prompt template, a LLM and an output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d59c2b9a-6450-4781-b4a6-89965493db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "<class 'langchain_anthropic.chat_models.ChatAnthropic'>\n",
      "<class 'langchain_core.output_parsers.string.StrOutputParser'>\n"
     ]
    }
   ],
   "source": [
    "print(type(template))\n",
    "print(type(claude_llm))\n",
    "print(type(output_parser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e9e9dd4-6b50-4f48-a2d9-2e9a9bd1833d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a chain with 3 steps\n",
    "chain = template | claude_llm | output_parser\n",
    "type(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55b5da82-f6af-447c-8fa6-20acc54c1e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the resopnse: <class 'str'>\n",
      "Here's a witty carrot joke:\n",
      "\n",
      "Why didn't the carrot go pro? Because he wasn't a-maize-ing enough.\n"
     ]
    }
   ],
   "source": [
    "# Again, use the chain by sending the dictionary to the first prompt template\n",
    "# Define an adjective and topic\n",
    "adj = \"witty\"\n",
    "top = \"carrots\"\n",
    "#\n",
    "# We start the chain by using the invoke() method.\n",
    "response = chain.invoke({\"adjective\":adj,\"topic\":top})\n",
    "# Check out the response now, already converted to a string.\n",
    "print(\"Type of the resopnse:\", type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b788b879-2372-40f3-9396-ca5e28f90723",
   "metadata": {},
   "source": [
    "## What we did:\n",
    "1. Created a LLM object inside of LangChain\n",
    "2. Created a prompt template object\n",
    "3. Created a 2-step chain and used it (prompt + llm)\n",
    "4. Created an ouput parser to convert AIMessage to a string\n",
    "5. Created a 3-step chain and used it (prompt + llm + output parser)\n",
    "\n",
    "[Top of Page](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f384316-9aec-4a55-ac31-cf806c2ce901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
