{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab54ea4-b48e-45ec-a4dc-3a18abbd74d8",
   "metadata": {},
   "source": [
    "## LangChain: Output Parsers for Structured data\n",
    "\n",
    "So far, we have just worked with the string data returned from a LLM. In this notebook we are going to ask for formated data and parse it first into JSON, then finally into a pandas dataframe, which is very common way to work with tabular data.\n",
    "\n",
    "### Table of Contents <a name=\"top\"></a>\n",
    "1. [Introduction to Pydantic](#pydantic)\n",
    "2. [Use a Pydantic model to structure a simple return from a LLM into JSON](#joke)\n",
    "3. [Build a pandas dataframe](#pandas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4210ac-3577-443e-8bb0-28183a803d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything we need up front\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import langchain\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c5dce8-037b-4eeb-9736-5b8e40ad41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Now you can access the environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "#\n",
    "# Not needed for this notebook\n",
    "# langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY'\n",
    "#\n",
    "# You can always just assign your variable directly, just not good practice to expose your key in a notebook\n",
    "# anthropic_api_key='sk-ant-api03....._AAA' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac09b33-e25c-454f-a77b-552277802fff",
   "metadata": {},
   "source": [
    "## Introduction to Pydantic:<a name=\"pydantic\"></a>\n",
    "Pydantic is a Python library that helps you handle data. It allows you to define the structure of your data using Python classes, and then it makes sure that the data you work with matches this structure.\n",
    "\n",
    "Here's an analogy: imagine you're running a club and you want to keep a list of all your members. For each member, you want to record their name, age, and email address. You could keep this information in a Python dictionary, like this:\n",
    "[Top of Page](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11895ea1-3898-4d58-8b29-a3cda52cc828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'User',\n",
       " 'type': 'object',\n",
       " 'properties': {'id': {'title': 'Id', 'type': 'integer'},\n",
       "  'name': {'title': 'Name', 'type': 'string'},\n",
       "  'age': {'title': 'Age', 'type': 'number'},\n",
       "  'email': {'title': 'Email', 'type': 'string'}},\n",
       " 'required': ['id', 'name', 'age', 'email']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pydantic allows you to define a data structure\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    age: float\n",
    "    email: str\n",
    "# View the schema for the data\n",
    "User.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555112de-bdb5-4ebc-80ce-cf94889493d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": 1, \"name\": \"LeBron\", \"age\": 39.999, \"email\": \"lebron@lakers.com\"}'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the User pydantic model\n",
    "user = User(id=1, name='LeBron', age=39.999, email='lebron@lakers.com')\n",
    "# Just have look at the user, it is a JSON object.\n",
    "user.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40122d50-701d-411f-99e2-1905406df86f",
   "metadata": {},
   "source": [
    "## Use a Pydantic model to structure a simple return from a LLM into JSON <a name=\"joke\"></a>\n",
    "In this section we we ask the LLM for a simple joke, then parse it into a structured JSON object.<BR>\n",
    "[Top of Page](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda25bce-8fad-4705-86eb-536079b4f6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Joke',\n",
       " 'type': 'object',\n",
       " 'properties': {'setup': {'title': 'Setup',\n",
       "   'description': 'question to set up a joke',\n",
       "   'type': 'string'},\n",
       "  'punchline': {'title': 'Punchline',\n",
       "   'description': 'answer to resolve the joke',\n",
       "   'type': 'string'}},\n",
       " 'required': ['setup', 'punchline']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a new data structure for a joke\n",
    "#\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "Joke.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8142bfb-8f2b-49d3-8892-8b51329fa2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up a parser give it your data structure\n",
    "joke_parser = JsonOutputParser(pydantic_object=Joke)\n",
    "joke_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f585c810-d327-470f-8efb-bc5a9086aeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'PromptTemplate',\n",
       " 'description': 'Prompt template for a language model.\\n\\nA prompt template consists of a string template. It accepts a set of parameters\\nfrom the user that can be used to generate a prompt for a language model.\\n\\nThe template can be formatted using either f-strings (default) or jinja2 syntax.\\n\\n*Security warning*: Prefer using `template_format=\"f-string\"` instead of\\n    `template_format=\"jinja2\"`, or make sure to NEVER accept jinja2 templates\\n    from untrusted sources as they may lead to arbitrary Python code execution.\\n\\n    As of LangChain 0.0.329, Jinja2 templates will be rendered using\\n    Jinja2\\'s SandboxedEnvironment by default. This sand-boxing should\\n    be treated as a best-effort approach rather than a guarantee of security,\\n    as it is an opt-out rather than opt-in approach.\\n\\n    Despite the sand-boxing, we recommend to never use jinja2 templates\\n    from untrusted sources.\\n\\nExample:\\n\\n    .. code-block:: python\\n\\n        from langchain_core.prompts import PromptTemplate\\n\\n        # Instantiation using from_template (recommended)\\n        prompt = PromptTemplate.from_template(\"Say {foo}\")\\n        prompt.format(foo=\"bar\")\\n\\n        # Instantiation using initializer\\n        prompt = PromptTemplate(input_variables=[\"foo\"], template=\"Say {foo}\")',\n",
       " 'type': 'object',\n",
       " 'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "  'input_variables': {'title': 'Input Variables',\n",
       "   'type': 'array',\n",
       "   'items': {'type': 'string'}},\n",
       "  'input_types': {'title': 'Input Types', 'type': 'object'},\n",
       "  'output_parser': {'$ref': '#/definitions/BaseOutputParser'},\n",
       "  'partial_variables': {'title': 'Partial Variables', 'type': 'object'},\n",
       "  'metadata': {'title': 'Metadata', 'type': 'object'},\n",
       "  'tags': {'title': 'Tags', 'type': 'array', 'items': {'type': 'string'}},\n",
       "  'template': {'title': 'Template', 'type': 'string'},\n",
       "  'template_format': {'title': 'Template Format',\n",
       "   'default': 'f-string',\n",
       "   'enum': ['f-string', 'mustache', 'jinja2'],\n",
       "   'type': 'string'},\n",
       "  'validate_template': {'title': 'Validate Template',\n",
       "   'default': False,\n",
       "   'type': 'boolean'}},\n",
       " 'required': ['input_variables', 'template'],\n",
       " 'definitions': {'BaseOutputParser': {'title': 'BaseOutputParser',\n",
       "   'description': 'Base class to parse the output of an LLM call.\\n\\nOutput parsers help structure language model responses.\\n\\nExample:\\n    .. code-block:: python\\n\\n        class BooleanOutputParser(BaseOutputParser[bool]):\\n            true_val: str = \"YES\"\\n            false_val: str = \"NO\"\\n\\n            def parse(self, text: str) -> bool:\\n                cleaned_text = text.strip().upper()\\n                if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\\n                    raise OutputParserException(\\n                        f\"BooleanOutputParser expected output value to either be \"\\n                        f\"{self.true_val} or {self.false_val} (case-insensitive). \"\\n                        f\"Received {cleaned_text}.\"\\n                    )\\n                return cleaned_text == self.true_val.upper()\\n\\n            @property\\n            def _type(self) -> str:\\n                return \"boolean_output_parser\"',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'}}}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a simple prompt template\n",
    "template = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": joke_parser.get_format_instructions()},\n",
    ")\n",
    "template.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7866b74f-7018-43e0-8f96-f6a2b0cd9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ChatGPT model\n",
    "openai_llm = ChatOpenAI(model='gpt-3.5-turbo', api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb90181b-2347-42ad-b12b-200020cf3f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "<class 'langchain_core.output_parsers.json.JsonOutputParser'>\n"
     ]
    }
   ],
   "source": [
    "# Now we have everything we need for a chain:\n",
    "print(type(template))\n",
    "print(type(openai_llm))\n",
    "print(type(joke_parser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1330ba2e-001d-4019-b35f-896b9314b92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So create the chain\n",
    "chain = template | openai_llm | joke_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dfd6125-978d-4825-9bd6-a69b3fd5aabf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Tell me a joke.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"Tell me a joke.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the user query.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"setup\\\": {\\\"title\\\": \\\"Setup\\\", \\\"description\\\": \\\"question to set up a joke\\\", \\\"type\\\": \\\"string\\\"}, \\\"punchline\\\": {\\\"title\\\": \\\"Punchline\\\", \\\"description\\\": \\\"answer to resolve the joke\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"setup\\\", \\\"punchline\\\"]}\\n```\\nTell me a joke.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] [936ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\n  \\\"setup\\\": \\\"Why was the math book sad?\\\",\\n  \\\"punchline\\\": \\\"Because it had too many problems.\\\"\\n}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\n  \\\"setup\\\": \\\"Why was the math book sad?\\\",\\n  \\\"punchline\\\": \\\"Because it had too many problems.\\\"\\n}\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"name\": null,\n",
      "            \"id\": \"run-d1f0a5e3-1b44-4453-bf8a-13fb8cd7ffa3-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 28,\n",
      "      \"prompt_tokens\": 206,\n",
      "      \"total_tokens\": 234\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_3b956da36b\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:JsonOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"setup\": \"Why was the math book sad?\",\n",
      "  \"punchline\": \"Because it had too many problems.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [948ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"setup\": \"Why was the math book sad?\",\n",
      "  \"punchline\": \"Because it had too many problems.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Create a query to send to the LLM\n",
    "joke_query = \"Tell me a joke.\"\n",
    "#\n",
    "# Now start the chain, but this time we will turn on the verbose mode so we can see what is happening.\n",
    "response = chain.invoke({\"query\": joke_query},config={'callbacks': [ConsoleCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f64b916-2aad-4578-83e8-67bcd4112254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# If everything went right, we now have a JSON/dictionary\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ae876d-6255-4072-b87d-d898480ba19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': 'Why was the math book sad?',\n",
       " 'punchline': 'Because it had too many problems.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OK, just have a look at the JSON object. Structured output!\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f675f-6229-483d-ae4e-bf6b7074bcfc",
   "metadata": {},
   "source": [
    "### Build a pandas dataframe <a name=\"pandas\"></a>\n",
    "Let's take a step in complexity. Now, we'll ask the LLM for some structured data and we'll convert that structured data into a pandas dataframe.<BR>\n",
    "[Top of Page](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcd2efa4-0880-420e-82d1-bf6b5afae389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'SP500Data',\n",
       " 'type': 'object',\n",
       " 'properties': {'year': {'title': 'Year', 'type': 'integer'},\n",
       "  'sp_500_index_value': {'title': 'Sp 500 Index Value', 'type': 'number'}},\n",
       " 'required': ['year', 'sp_500_index_value']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define pydantic desired data structure.\n",
    "#\n",
    "class SP500Data(BaseModel):\n",
    "    year: int\n",
    "    sp_500_index_value: float\n",
    "\n",
    "class SP500Index(BaseModel):\n",
    "    data: List[SP500Data]\n",
    "SP500Data.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4807fc1f-8e67-44de-aaec-44ccfe51d526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"year\": {\"title\": \"Year\", \"type\": \"integer\"}, \"sp_500_index_value\": {\"title\": \"Sp 500 Index Value\", \"type\": \"number\"}}, \"required\": [\"year\", \"sp_500_index_value\"]}\\n```'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up a new parser with our data structure\n",
    "sp_parser = JsonOutputParser(pydantic_object=SP500Data)\n",
    "sp_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "757fcb90-554f-47f5-a7ba-3c2f35ff9281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "<class 'langchain_core.output_parsers.json.JsonOutputParser'>\n"
     ]
    }
   ],
   "source": [
    "# Now we have everything we need for a new chain:\n",
    "print(type(template)) # We can use the same template\n",
    "print(type(openai_llm))\n",
    "print(type(sp_parser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "381a7b3a-b6b3-4d83-b639-f14fec2ca338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new chain using our new configured parser\n",
    "sp_chain = template | openai_llm | sp_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31e8d9cd-b6c1-490e-96cf-2e35d506a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"\\nPlease generate a table of hypothetical data of the S&P 500 stock market index value\\nfor the end of each year for the period 1980 - 1985? Please format this data JSON.\\n\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"\\nPlease generate a table of hypothetical data of the S&P 500 stock market index value\\nfor the end of each year for the period 1980 - 1985? Please format this data JSON.\\n\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 2:prompt:PromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Answer the user query.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\\\"properties\\\": {\\\"foo\\\": {\\\"title\\\": \\\"Foo\\\", \\\"description\\\": \\\"a list of strings\\\", \\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}}, \\\"required\\\": [\\\"foo\\\"]}\\nthe object {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]} is a well-formatted instance of the schema. The object {\\\"properties\\\": {\\\"foo\\\": [\\\"bar\\\", \\\"baz\\\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\\\"properties\\\": {\\\"setup\\\": {\\\"title\\\": \\\"Setup\\\", \\\"description\\\": \\\"question to set up a joke\\\", \\\"type\\\": \\\"string\\\"}, \\\"punchline\\\": {\\\"title\\\": \\\"Punchline\\\", \\\"description\\\": \\\"answer to resolve the joke\\\", \\\"type\\\": \\\"string\\\"}}, \\\"required\\\": [\\\"setup\\\", \\\"punchline\\\"]}\\n```\\n\\nPlease generate a table of hypothetical data of the S&P 500 stock market index value\\nfor the end of each year for the period 1980 - 1985? Please format this data JSON.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] [3.25s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"{\\n  \\\"data\\\": [\\n    {\\n      \\\"year\\\": 1980,\\n      \\\"s&p_500_index_value\\\": 135.76\\n    },\\n    {\\n      \\\"year\\\": 1981,\\n      \\\"s&p_500_index_value\\\": 137.55\\n    },\\n    {\\n      \\\"year\\\": 1982,\\n      \\\"s&p_500_index_value\\\": 140.64\\n    },\\n    {\\n      \\\"year\\\": 1983,\\n      \\\"s&p_500_index_value\\\": 165.37\\n    },\\n    {\\n      \\\"year\\\": 1984,\\n      \\\"s&p_500_index_value\\\": 167.24\\n    },\\n    {\\n      \\\"year\\\": 1985,\\n      \\\"s&p_500_index_value\\\": 211.28\\n    }\\n  ]\\n}\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"{\\n  \\\"data\\\": [\\n    {\\n      \\\"year\\\": 1980,\\n      \\\"s&p_500_index_value\\\": 135.76\\n    },\\n    {\\n      \\\"year\\\": 1981,\\n      \\\"s&p_500_index_value\\\": 137.55\\n    },\\n    {\\n      \\\"year\\\": 1982,\\n      \\\"s&p_500_index_value\\\": 140.64\\n    },\\n    {\\n      \\\"year\\\": 1983,\\n      \\\"s&p_500_index_value\\\": 165.37\\n    },\\n    {\\n      \\\"year\\\": 1984,\\n      \\\"s&p_500_index_value\\\": 167.24\\n    },\\n    {\\n      \\\"year\\\": 1985,\\n      \\\"s&p_500_index_value\\\": 211.28\\n    }\\n  ]\\n}\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"name\": null,\n",
      "            \"id\": \"run-dbdd9636-7f62-4bcd-a9e1-05b69626248a-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 165,\n",
      "      \"prompt_tokens\": 242,\n",
      "      \"total_tokens\": 407\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": \"fp_3b956da36b\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:JsonOutputParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence > 4:parser:JsonOutputParser] [2ms] Exiting Parser run with output:\n",
      "\u001b[0m{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"year\": 1980,\n",
      "      \"s&p_500_index_value\": 135.76\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1981,\n",
      "      \"s&p_500_index_value\": 137.55\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1982,\n",
      "      \"s&p_500_index_value\": 140.64\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1983,\n",
      "      \"s&p_500_index_value\": 165.37\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1984,\n",
      "      \"s&p_500_index_value\": 167.24\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1985,\n",
      "      \"s&p_500_index_value\": 211.28\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RunnableSequence] [3.26s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"data\": [\n",
      "    {\n",
      "      \"year\": 1980,\n",
      "      \"s&p_500_index_value\": 135.76\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1981,\n",
      "      \"s&p_500_index_value\": 137.55\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1982,\n",
      "      \"s&p_500_index_value\": 140.64\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1983,\n",
      "      \"s&p_500_index_value\": 165.37\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1984,\n",
      "      \"s&p_500_index_value\": 167.24\n",
      "    },\n",
      "    {\n",
      "      \"year\": 1985,\n",
      "      \"s&p_500_index_value\": 211.28\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# You need to be very specific with your LLM prompt. \n",
    "# I tested this out in a web chat until I was happy with what I was getting back.\n",
    "\n",
    "stock_query='''\n",
    "Please generate a table of hypothetical data of the S&P 500 stock market index value\n",
    "for the end of each year for the period 1980 - 1985? Please format this data JSON.\n",
    "'''\n",
    "# Start the chain in verbose mode\n",
    "response = chain.invoke({\"query\": stock_query}, config={'callbacks': [ConsoleCallbackHandler()]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c363c90f-cd28-4770-a9f9-36f9e45f831f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [{'year': 1980, 's&p_500_index_value': 135.76},\n",
       "  {'year': 1981, 's&p_500_index_value': 137.55},\n",
       "  {'year': 1982, 's&p_500_index_value': 140.64},\n",
       "  {'year': 1983, 's&p_500_index_value': 165.37},\n",
       "  {'year': 1984, 's&p_500_index_value': 167.24},\n",
       "  {'year': 1985, 's&p_500_index_value': 211.28}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the raw response, looks like JSON!\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccb7e54e-6f97-4432-aa36-046df935c65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': 1980, 's&p_500_index_value': 135.76},\n",
       " {'year': 1981, 's&p_500_index_value': 137.55},\n",
       " {'year': 1982, 's&p_500_index_value': 140.64},\n",
       " {'year': 1983, 's&p_500_index_value': 165.37},\n",
       " {'year': 1984, 's&p_500_index_value': 167.24},\n",
       " {'year': 1985, 's&p_500_index_value': 211.28}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at just the 'data' key\n",
    "response['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d081f864-7bbf-4ab2-a7ba-325e2b06edea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>s&amp;p_500_index_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1980</td>\n",
       "      <td>135.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1981</td>\n",
       "      <td>137.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1982</td>\n",
       "      <td>140.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>165.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984</td>\n",
       "      <td>167.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1985</td>\n",
       "      <td>211.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  s&p_500_index_value\n",
       "0  1980               135.76\n",
       "1  1981               137.55\n",
       "2  1982               140.64\n",
       "3  1983               165.37\n",
       "4  1984               167.24\n",
       "5  1985               211.28"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With this structured data, we can easily build a pandas dataframe to work with the data.\n",
    "#\n",
    "# Create a DataFrame from the LLM response\n",
    "df = pd.DataFrame(response['data'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4951e3d-01aa-4550-b68c-822e1b3976b4",
   "metadata": {},
   "source": [
    "### What we did\n",
    "1. Learned how to create a data structure using Pydantic\n",
    "2. Learned how to format LLM data into a simple JSON-structured joke: setup and punchline\n",
    "3. Leared how to format tabular data from a LLM into JSON format.\n",
    "4. Converted the JSON into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe86440-66c2-4b5e-b40e-07c75d8dcbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
