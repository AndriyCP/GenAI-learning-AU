{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ab54ea4-b48e-45ec-a4dc-3a18abbd74d8",
   "metadata": {},
   "source": [
    "## Still under development, not ready for students to use.\n",
    "## Chat Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145301f1-c3bd-4761-86fe-15c91efe0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TBD\n",
    "#https://python.langchain.com/docs/get_started/quickstart/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4210ac-3577-443e-8bb0-28183a803d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c5dce8-037b-4eeb-9736-5b8e40ad41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Now you can access the environment variables\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "#\n",
    "# Not needed for this notebook\n",
    "# langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
    "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# huggingface_api_key = os.getenv('HUGGINGFACE_API_KEY'\n",
    "#\n",
    "# You can always just assign your variable directly, just not good practice to expose your key in a notebook\n",
    "# anthropic_api_key='sk-ant-api03....._AAA' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00efb4c0-9029-4866-81e5-d78b4b5c3643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptInput(user_input=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert in Large Language Models, especially working in Python. Your name is Clyde.\"),\n",
    "    (\"human\", \"Greatings Clyde, Please be ready to answer my questions about using LLMs with Python.\"),\n",
    "    (\"ai\", \"Yes, ready, willing and able.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "template.input_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f947f7b3-dbbf-45c3-b82a-90b1b9cf336a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are an expert in Large Language Models, especially working in Python. Your name is Clyde.'), HumanMessage(content='Greatings Clyde, Please be ready to answer my questions about using LLMs with Python.'), AIMessage(content='Yes, ready, willing and able.'), HumanMessage(content='Clyde, please explain embeddings in a simple and clear way.')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_input=\"Clyde, please explain embeddings in a simple and clear way.\"\n",
    "template.invoke({\"user_input\": raw_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc0ea95-5aab-4539-a7e9-e52821172ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52b1e97a-63b7-48a4-91f4-f0efdaa10d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "openai_llm = ChatOpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "951de2e1-6cc4-4e23-9895-97b8ef5eb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output parser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdc34671-913b-43ff-a4b5-7b8766f6a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | openai_llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93b8233c-4ca4-4045-a9fe-63510dcb9c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the chain\n",
    "raw_input=\"Clyde, please explain a LLM vector store and when I might use it.\"\n",
    "response = chain.invoke({\"user_input\": raw_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f0c2724-a999-4492-a6b8-23f97db2eee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model (LLM) vector store is a data structure that stores vector representations of words or phrases generated by a pre-trained language model such as BERT, GPT, or Word2Vec. These vector representations capture the semantic meaning of the words or phrases in a high-dimensional vector space.\n",
      "\n",
      "You might use a LLM vector store when you need to quickly retrieve vector representations of words or phrases for various natural language processing tasks such as semantic similarity, text classification, or clustering. By using pre-trained vectors from a LLM vector store, you can leverage the semantic knowledge learned by the language model during pre-training without the need to train a new model from scratch.\n",
      "\n",
      "In Python, you can use libraries such as Hugging Face Transformers or Gensim to work with LLM vector stores and easily access pre-trained vector representations for words or phrases in your NLP projects.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e12f19-240e-4466-a64e-952cd0bff1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to keep history?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7379db-c28f-496c-addf-d355412d172f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be6144-cc69-49d9-a79e-8957464cfff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeef46a-53bd-4a64-bd4d-f1169363fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1953c6-cf90-4928-8c34-cadc6e542ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc063f-0ea2-46ac-ab5e-b15bc9c2c324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d373397-8a67-4865-95a4-5da82d4604ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91a94e-ae08-45fc-9c2c-c55ebf016db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "openai_llm = ChatOpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d732dfc-b4bf-4848-b308-52842a5f1b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf93b3-b099-49e4-8b5b-9676d7bf0b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain\n",
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18291c1-ffd5-4ca4-a9a4-d29c968bae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke\n",
    "myInput= {\"input\": \"how can langsmith help with testing?\"}\n",
    "#response = chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "response = chain.invoke(myInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96a4172-fd4f-4ee7-9096-ef8cd764c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6479f2-5fe4-484e-b920-77623b1f3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1783eb1-1c9c-4f30-8a28-e309f2448392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defimne the 3-step-chain\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e7ba3-a16c-4a84-8934-d675dc9ca44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the response is the result of the 3-steps\n",
    "response = chain.invoke(myInput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e812a0-0329-4238-8d5a-4bc1d4acff8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba941d7e-6d44-4018-8544-ae9e7b3a2ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
