{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1af6eb-2b2c-4c61-8c7a-215ee1e1f1e8",
   "metadata": {},
   "source": [
    "## Calling Anthropic's Claude using a REST API\n",
    "For students learning about AI, leveraging the Anthropic Claude model through a REST API can be a valuable way to explore and integrate advanced natural language processing capabilities into their applications. The Claude model, developed by Anthropic, is accessible through a well-documented REST API that allows developers to send text prompts and receive responses generated by the powerful language model. By understanding how to interact with this type of AI-powered REST API, students can expand the functionality of their projects, experiment with different use cases, and gain practical experience in incorporating state-of-the-art AI technologies into real-world applications.\n",
    "### Table of Contents\n",
    "1. [Setup your Anthropic API key](#setup)\n",
    "2. [Make a simple API call to one of Claude's models](#simple)\n",
    "3. [A few options for using the API](#options)\n",
    "4. [Your assignment](#assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b669b4-fb42-47cb-af5f-f6f47f2cbf70",
   "metadata": {},
   "source": [
    "## Setup your Anthropic API key<a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f7f885-9ee2-4810-95ff-9c6f85da456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# This package is not installed in our Sagemaker image.\n",
    "# Everytime you researt this jupyterlab, you will have to reinstall it.\n",
    "%pip install python-dotenv\n",
    "# Now import the objects we need\n",
    "from dotenv import load_dotenv\n",
    "# Other needed packages to import\n",
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30712831-2b1a-46ca-b4f5-c63aea7d8c12",
   "metadata": {},
   "source": [
    "To store your API key for use with the requests package:\n",
    "- Get the key from your account on https://console.anthropic.com. It will look something like: \"\"sk-ant-api03-Iu4 ... U37M\"\n",
    "- Now, open a terminal from the jupyter Launcher\n",
    "    - Use the nano text editor (or any other editor)\n",
    "    - Create a .env file (that is a file with the exact name \".env\" (files that start with '.' are hidden by default\n",
    "    - Add a line that looks like this: ANTHROPIC_API_KEY=\"your_key\"\n",
    "       - Insert your key in double-quotes\n",
    "    - Save the file and exit the text editor. In nano: Save (ctl-o), Exit (ctl-x)\n",
    "\n",
    "<P>\n",
    "Next we will load this key into this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce74efc3-5f13-4486-b4fb-9fae3fe55e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Now you can access the environment variable\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# You can print the key to make sure it is there, but I get nervous when I see a key printed somewhere.... Someone could steal it!\n",
    "#print(anthropic_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc85cf-7502-4afd-80b2-d7d391a692c0",
   "metadata": {},
   "source": [
    "## Make a simple API call to one of Claude's models<a name=\"simple\"></a>\n",
    "If you want to know more: https://docs.anthropic.com/claude/reference/messages_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38deb48e-c33d-4346-9ed8-b10700de087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API endpoint:\n",
    "url = 'https://api.anthropic.com/v1/messages'\n",
    "# Define the headers\n",
    "headers = {\n",
    "    'x-api-key': anthropic_api_key,\n",
    "    'anthropic-version': '2023-06-01',\n",
    "    'content-type': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa8dba5-94de-49a4-9f66-90be53d04288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229', # Select a model from here: https://docs.anthropic.com/claude/docs/models-overview\n",
    "    'max_tokens': 1024,\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': 'Write a blog post about large language models.'}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c31299-abcb-4dee-9ca6-51e54f3d6304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Make the API POST request.\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable\n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "# When you execute this cell, you are paying to inference the model. It will deduct money from your account.\n",
    "# Therefore, I usually do anything in this cell other than store the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a43b64-72e8-4872-b655-7e64a59d95fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a draft blog post about large language models:\n",
      "\n",
      "Title: The Rise of Large Language Models and Their Potential Impact\n",
      "\n",
      "Over the past few years, we've witnessed the rapid emergence of large language models like GPT-3, BERT, and PaLM that are capable of understanding and generating human-like text on a wide range of topics. These models are trained on vast datasets of online text from sources like books, articles, and websites, allowing them to develop nuanced abilities in areas like question answering, text summarization, translation, and even creative writing.\n",
      "\n",
      "At their core, large language models use machine learning techniques, specifically transformer-based neural networks, to identify patterns in the training data and make predictions about which words or sequences of words are most likely to come next given the previous context. What sets them apart is not just the complexity of the underlying model architecture, but the sheer scale of the datasets they are trained on, which can include billions or even trillions of words.\n",
      "\n",
      "The results of these models can be remarkable - they demonstrate nuanced communication abilities and logical reasoning skills that were unimaginable with previous generations of language technology. For example, GPT-3 can engage in multi-turn dialogue, answer follow-up questions, and even attempt to write poetry, short stories, or code when prompted. PaLM combines text with reasoning about images, code, and other modalities. Their fluency gives the impression of deeper comprehension and understanding.\n",
      "\n",
      "However, it's important to understand that despite their sophistication, current large language models are still fundamentally pattern matchers without true semantic understanding of the content they produce. While uncannily human-like at times, the models can also generate outputs that are nonsensical, untruthful or biased. They are highly adept at linguistic mimicry but their training data and inner workings remain opaque \"black boxes.\" There remain open questions around their reliability, accountability, and potential negative impacts like spreading misinformation or codifying social biases.\n",
      "\n",
      "Moving forward, researchers are exploring ways to improve the transparency and controllability of these models, as well as techniques to make them more truthful, ethical, and robust. There's also interest in models that combine perception abilities with language understanding -- a step towards more generally capable AI agents.\n",
      "\n",
      "Whether large language models ultimately represent a stepping stone or an academic detour in the quest for advanced AI remains to be seen. But their rapid progression has already impacted fields like writing, education, and programming -- a harbinger of the potential technological shifts yet to come from innovations in AI and machine learning.\n"
     ]
    }
   ],
   "source": [
    "# Look at the resposne\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395cf782-805a-4bcc-96fa-83a31bf8d5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01VPhWHeiy5ezXVDMohDpLoD',\n",
       " 'type': 'message',\n",
       " 'role': 'assistant',\n",
       " 'model': 'claude-3-sonnet-20240229',\n",
       " 'stop_sequence': None,\n",
       " 'usage': {'input_tokens': 16, 'output_tokens': 547},\n",
       " 'content': [{'type': 'text',\n",
       "   'text': 'Here is a draft blog post about large language models:\\n\\nTitle: The Rise of Large Language Models and Their Potential Impact\\n\\nOver the past few years, we\\'ve witnessed the rapid emergence of large language models like GPT-3, BERT, and PaLM that are capable of understanding and generating human-like text on a wide range of topics. These models are trained on vast datasets of online text from sources like books, articles, and websites, allowing them to develop nuanced abilities in areas like question answering, text summarization, translation, and even creative writing.\\n\\nAt their core, large language models use machine learning techniques, specifically transformer-based neural networks, to identify patterns in the training data and make predictions about which words or sequences of words are most likely to come next given the previous context. What sets them apart is not just the complexity of the underlying model architecture, but the sheer scale of the datasets they are trained on, which can include billions or even trillions of words.\\n\\nThe results of these models can be remarkable - they demonstrate nuanced communication abilities and logical reasoning skills that were unimaginable with previous generations of language technology. For example, GPT-3 can engage in multi-turn dialogue, answer follow-up questions, and even attempt to write poetry, short stories, or code when prompted. PaLM combines text with reasoning about images, code, and other modalities. Their fluency gives the impression of deeper comprehension and understanding.\\n\\nHowever, it\\'s important to understand that despite their sophistication, current large language models are still fundamentally pattern matchers without true semantic understanding of the content they produce. While uncannily human-like at times, the models can also generate outputs that are nonsensical, untruthful or biased. They are highly adept at linguistic mimicry but their training data and inner workings remain opaque \"black boxes.\" There remain open questions around their reliability, accountability, and potential negative impacts like spreading misinformation or codifying social biases.\\n\\nMoving forward, researchers are exploring ways to improve the transparency and controllability of these models, as well as techniques to make them more truthful, ethical, and robust. There\\'s also interest in models that combine perception abilities with language understanding -- a step towards more generally capable AI agents.\\n\\nWhether large language models ultimately represent a stepping stone or an academic detour in the quest for advanced AI remains to be seen. But their rapid progression has already impacted fields like writing, education, and programming -- a harbinger of the potential technological shifts yet to come from innovations in AI and machine learning.'}],\n",
       " 'stop_reason': 'end_turn'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look closer at the entire response. Other data is included\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f9c82-19f8-4603-a913-83b436f0dfbc",
   "metadata": {},
   "source": [
    "## A few options for using the API<a name=\"options\"></a>\n",
    "- max_tokens\n",
    "- temperature\n",
    "- system prompt\n",
    "- Multiple conversational turns\n",
    "- Using the conversation history in multiple API calls (keeping the context of the conversation active)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b87d21-af97-40c5-ac0d-8f5ef627322e",
   "metadata": {},
   "source": [
    "#### max_tokens\n",
    "When using the Anthropic Claude API, the `max_tokens` parameter is an important setting that allows you to control the length of the generated text response. The `max_tokens` parameter specifies the maximum number of tokens (words or word pieces) that the model should generate in the response. This is useful for preventing the model from generating excessively long or open-ended responses, which can help manage the response size and cost when using the API. By adjusting the `max_tokens` value, you can balance the desired level of detail and conciseness in the generated text to best fit the needs of your application. Understanding how to effectively leverage the `max_tokens` parameter is an important consideration when integrating the powerful Claude language model through the REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b280fc6-2bbd-417b-8b0c-61c9597b5aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Max tokens\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 100, # short, interrupted response\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"Can you explain Artificial Neural Networks plain English?\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable\n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1530d0b-ae3e-487f-996e-a6c37974b375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'll try to explain artificial neural networks in plain English.\n",
      "\n",
      "Artificial neural networks are computing systems that are inspired by the way the human brain works. Just like our brain is made up of interconnected neurons, artificial neural networks consist of interconnected nodes or units.\n",
      "\n",
      "These nodes are organized into layers – an input layer, hidden layers, and an output layer. The input layer receives the data (like images, text, or numbers) that needs to be processed. This data then\n",
      "\n",
      "\n",
      "Why the response ended: max_tokens\n",
      "Token usage: {'input_tokens': 17, 'output_tokens': 100}\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)\n",
    "print('\\n\\nWhy the response ended:', response.json()['stop_reason'])\n",
    "print('Token usage:', response.json()['usage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ff4e2-8311-4888-b256-b27f605ddc95",
   "metadata": {},
   "source": [
    "#### temperature\n",
    "The `temperature` parameter in the Anthropic Claude API is a setting that controls the \"creativity\" or \"randomness\" of the generated text. Temperature is a value between 0 and 1 that affects the model's probability distribution when choosing the next token in the output. \n",
    "\n",
    "A lower temperature (closer to 0) results in more deterministic, logical, and \"safer\" text generation, as the model will tend to choose the most probable next tokens based on the training data. This can be useful for generating text that needs to adhere to specific guidelines or patterns.\n",
    "\n",
    "Conversely, a higher temperature (closer to 1) introduces more randomness and creativity into the text generation process. The model will explore a wider range of possible next tokens, leading to more diverse, unexpected, and imaginative outputs. This can be beneficial for tasks like creative writing, brainstorming, or open-ended exploration.\n",
    "\n",
    "By adjusting the `temperature` parameter, users of the Claude API can control the balance between coherence/safety and creativity/unpredictability in the model's generated text, allowing them to fine-tune the output to best suit their specific application needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03b2455c-f55f-4a51-894b-d3f7d81f3e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Temperature (low temperature, less random, more deterministic or conservative)\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 200, \n",
    "    # Low temperature (more deterministic, less random)\n",
    "    'temperature':0,\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"List several job options for Cal Poly Data Analytics Students.\"},\n",
    "  ]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable    \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35865295-aec5-4237-9eab-d824cff84cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cal Poly Data Analytics students have a wide range of job options available to them upon graduation. Here are several potential career paths:\n",
      "\n",
      "1. Data Analyst: Companies across various industries, such as finance, healthcare, marketing, and technology, hire data analysts to collect, analyze, and interpret data to support decision-making processes.\n",
      "\n",
      "2. Business Intelligence Analyst: These professionals are responsible for transforming raw data into meaningful insights and reports that help organizations make informed business decisions.\n",
      "\n",
      "3. Data Scientist: Data scientists combine statistical and machine learning techniques to extract valuable insights from large and complex datasets, often working on predictive modeling and advanced analytics projects.\n",
      "\n",
      "4. Marketing Analyst: Marketing analysts use data analytics to understand consumer behavior, market trends, and campaign effectiveness, helping companies develop effective marketing strategies.\n",
      "\n",
      "5. Operations Research Analyst: These analysts use analytical methods to help organizations solve complex problems, improve processes, and optimize resource allocation.\n",
      "\n",
      "6. Financial Analyst: Financial\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd883f96-e3be-4a0f-b6ff-16f31d8519f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Temperature (High temperature, more random, less deterministic or less conservative)\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 100, \n",
    "    # High temperature (more random, more creative)\n",
    "    'temperature':1.0,\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"List several job options for Cal Poly Data Analytics Students.\"},\n",
    "  ]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable        \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267d66c0-63c0-4a95-94cf-a80151d81be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cal Poly Data Analytics students can pursue various job opportunities upon graduation. Here are several potential job options for them:\n",
      "\n",
      "1. Data Analyst\n",
      "2. Business Intelligence Analyst\n",
      "3. Data Scientist\n",
      "4. Data Engineer\n",
      "5. Analytics Consultant\n",
      "6. Marketing Analyst\n",
      "7. Operations Analyst\n",
      "8. Financial Analyst\n",
      "9. Risk Analyst\n",
      "10. Supply Chain Analyst\n",
      "11. Healthcare Data Analyst\n",
      "12. Business Analyst\n",
      "13.\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18621349-9861-423b-b1b8-76caf844ea8f",
   "metadata": {},
   "source": [
    "#### system prompt\n",
    "The `system_prompt` parameter in the Anthropic Claude API allows you to provide the model with an initial context or instructions that can guide the generation of the response. The `system_prompt` sets the tone, personality, and objectives for the AI assistant before it generates the output. \n",
    "\n",
    "By crafting a thoughtful `system_prompt`, you can direct the model to respond in a specific way, such as adopting a particular voice, adhering to certain guidelines, or focusing on particular topics or tasks. This can be especially useful for creating custom AI assistants or tailoring the model's behavior to your application's needs.\n",
    "\n",
    "The `system_prompt` parameter is a powerful tool that enables you to customize the Claude API to generate responses that are aligned with your desired outcomes, making it a key consideration when integrating the model into your applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b275ffbd-8fba-4e18-ad2d-db61342aa208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# system prompts: https://docs.anthropic.com/claude/docs/system-prompts\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 200, \n",
    "    'system': \"Respond as a high school guidance counselor talking with freshman students.\",\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"What are the advantages to attending Cal Poly for college?\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Extract just the generated text\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable            \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "174cc33f-e5a0-404f-b17b-15c72da5e34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some potential advantages of attending Cal Poly as a college student:\n",
      "\n",
      "- Excellent academic programs - Cal Poly is renowned for its strong programs in fields like engineering, architecture, agriculture, business and liberal arts. The learn-by-doing approach provides hands-on education.\n",
      "\n",
      "- Polytechnic focus - As a polytechnic university, Cal Poly emphasizes preparing students for professional careers through a technical, scientific and applied approach.\n",
      "\n",
      "- Location - Cal Poly's campus is located in San Luis Obispo, a beautiful area on the California central coast with a great college town atmosphere. The weather and surrounding environment are very attractive.\n",
      "\n",
      "- Prestige/Reputation - Cal Poly is consistently ranked among the top public master's level universities in the West. Employers actively recruit Cal Poly graduates.\n",
      "\n",
      "- Learn-by-Doing Philosophy - Students get practical skills through projects, internships, competitions and labs integrated into the curriculum.\n",
      "\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e13eea6e-18c3-4403-849e-f244e53bc2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# system prompt\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 100, \n",
    "    'system': \"Respond as high school freshman talking to a peer.\",\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"What are the advantages to attending Cal Poly for college?\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable             \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22ac661e-c1fe-43f2-b6f7-9057f71ee6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*clears throat and adjusts backpack strap*\n",
      "\n",
      "Yo, Cal Poly is a pretty sweet school from what I've heard. Some major pros are:\n",
      "\n",
      "- Their \"learn by doing\" philosophy means you get a ton of hands-on experience and projects, which is clutch for finding a good job after college.\n",
      "\n",
      "- They have dope programs in engineering, agriculture, business, and other technical fields. Their grads get hired like crazy.\n",
      "\n",
      "- The campus\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc317e-959f-46eb-b8fe-518563b611cc",
   "metadata": {},
   "source": [
    "#### multiple conversation turns\n",
    "When using the Anthropic Claude API, the ability to maintain multiple conversation turns is an important feature. This allows you to provide the model with a conversational context, where each subsequent request builds upon the previous responses. The API supports storing this conversational state, enabling the model to understand and respond to the evolving context. This can be particularly useful for creating more natural, coherent, and contextual interactions between the user and the AI assistant. By leveraging multiple conversation turns, you can create more engaging and informative dialogues that draw upon the model's accumulated knowledge and understanding of the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0c7408b-3e24-4959-8260-c8ad7c6e47ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Multiple conversational turns: https://docs.anthropic.com/claude/reference/messages-examples#multiple-conversational-turns\n",
    "# Define the data\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 200,\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"I have an AI question, are you ready?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Hi, I'm Claude an AI assistant, so I know a lot about it. Please, please ask me anything about AI.\"},\n",
    "  {\"role\": \"user\", \"content\": \"Can you explain Artificial Neural Networks plain English, including an analogy?\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable       \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "691492f3-55f1-409a-9c75-2f359e36f4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to explain artificial neural networks in plain English with an analogy.\n",
      "\n",
      "An artificial neural network is a computational model inspired by the way the human brain processes information. Just like the brain is made up of interconnected neurons, an artificial neural network consists of numerous interconnected nodes (artificial neurons) that work together to perform a specific task.\n",
      "\n",
      "Here's an analogy to help understand it better:\n",
      "\n",
      "Imagine you're trying to get donations for a charity event. You have a team of volunteers going door-to-door in a neighborhood. Each volunteer represents a node in the neural network.\n",
      "\n",
      "At each house, the volunteer looks for certain features, like the size of the house, the car in the driveway, or the presence of a \"no soliciting\" sign. These features are like the inputs to the node.\n",
      "\n",
      "Based on these inputs, and some rules or weights assigned to each input, the volunteer decides whether to knock on that door or\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a54f9-6312-4bab-86a6-7f0f5f3c92b3",
   "metadata": {},
   "source": [
    "#### Using the conversation history in multiple API calls\n",
    "The Anthropic Claude API supports the ability to maintain and utilize conversation history across multiple API calls. By passing the conversation history as part of each subsequent request, the model can reference and build upon the prior context, resulting in more coherent and contextual responses. Leveraging the conversation history is particularly useful for tasks that require an ongoing dialogue, such as open-ended Q&A, task completion, or collaborative ideation. This feature allows you to create more natural and engaging interactions, where the AI assistant can demonstrate an understanding of the discussion and provide relevant and tailored responses based on the evolving conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7df1c1e6-a67b-4eec-afa2-a45589ba3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Create a list to keep the API text responses\n",
    "message_lst = [] #empty list\n",
    "# Define the data\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 200,\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"Please explain the difference between Artifical Intelligence and Machine Learning.\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable           \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "# Keep a history: append the text to the list\n",
    "message_lst.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d87752b-dc9b-4ce9-bb33-32b446007e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry: 1 \n",
      " Text: Artificial Intelligence (AI) and Machine Learning (ML) are related but distinct concepts. Here's an explanation of the difference between the two:\n",
      "\n",
      "Artificial Intelligence (AI):\n",
      "AI is a broad field that encompasses the theory and development of computer systems capable of performing tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. AI aims to create intelligent machines that can mimic or even surpass human cognitive abilities.\n",
      "\n",
      "AI can be divided into two main categories:\n",
      "\n",
      "1. Narrow AI or Weak AI: This refers to AI systems designed to perform specific tasks within a narrow domain, such as playing chess, recognizing faces, or driving a car in certain conditions.\n",
      "\n",
      "2. Artificial General Intelligence (AGI) or Strong AI: This refers to hypothetical AI systems that can match or exceed human intelligence across a wide range of domains, exhibiting reasoning, problem-solving, and learning capabilities similar to or beyond those \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at our current list of responses\n",
    "for i,r in enumerate(message_lst):\n",
    "    print('Entry:', i+1, '\\n','Text:', r,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b0080f0-2a4a-4b10-823e-bd4832146e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Pass the history back into the assistant with a follow-up instruction.\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 1024,\n",
    "    'messages': [\n",
    "        {\"role\": \"user\", \"content\": \"Please explain the difference between Artifical Intelligence and Machine Learning.\"},\n",
    "        # Pass in the history\n",
    "        {\"role\": \"assistant\", \"content\": \" \".join(message_lst)}, # Combine all messages into a single string\n",
    "        # Give further instructions\n",
    "        {\"role\": \"user\", \"content\": \"Please reduce this explaination to a single paragraph.\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200:\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable            \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "# Append to the end of the list\n",
    "message_lst.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00654edd-7846-4caf-8437-f4d12f585428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry: 1 \n",
      " Text: Artificial Intelligence (AI) and Machine Learning (ML) are related but distinct concepts. Here's an explanation of the difference between the two:\n",
      "\n",
      "Artificial Intelligence (AI):\n",
      "AI is a broad field that encompasses the theory and development of computer systems capable of performing tasks that typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation. AI aims to create intelligent machines that can mimic or even surpass human cognitive abilities.\n",
      "\n",
      "AI can be divided into two main categories:\n",
      "\n",
      "1. Narrow AI or Weak AI: This refers to AI systems designed to perform specific tasks within a narrow domain, such as playing chess, recognizing faces, or driving a car in certain conditions.\n",
      "\n",
      "2. Artificial General Intelligence (AGI) or Strong AI: This refers to hypothetical AI systems that can match or exceed human intelligence across a wide range of domains, exhibiting reasoning, problem-solving, and learning capabilities similar to or beyond those \n",
      "\n",
      "\n",
      "Entry: 2 \n",
      " Text: Artificial Intelligence (AI) is a broad field that aims to create intelligent machines capable of performing tasks that typically require human intelligence. Machine Learning (ML) is a subset of AI that focuses on developing algorithms and statistical models that allow systems to learn from data and improve their performance on a specific task over time, without being explicitly programmed. While AI encompasses various techniques and approaches to mimic human cognitive abilities, ML emphasizes the ability to learn and adapt by leveraging algorithms that can automatically identify patterns in data. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at our current list of responses\n",
    "for i,r in enumerate(message_lst):\n",
    "    print('Entry:', i+1, '\\n','Text:', r,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2cb0d-e29d-4a7c-a143-427b7f09ab3e",
   "metadata": {},
   "source": [
    "## Your assignment:<a name=\"assignment\"></a>\n",
    "Using the examples above, create 3 unique API calls (different than my examples) using a combination of parameters and techniques. Just print your resopnses just as I have done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46160187-bac0-4a3c-971f-f22ba4166862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4da9dd-37e4-4829-9dbe-2615b0e0859b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
