{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1af6eb-2b2c-4c61-8c7a-215ee1e1f1e8",
   "metadata": {},
   "source": [
    "## Calling Anthropic's Claude using a REST API\n",
    "For students learning about AI, leveraging the Anthropic Claude model through a REST API can be a valuable way to explore and integrate advanced natural language processing capabilities into their applications. The Claude model, developed by Anthropic, is accessible through a well-documented REST API that allows developers to send text prompts and receive responses generated by the powerful language model. By understanding how to interact with this type of AI-powered REST API, students can expand the functionality of their projects, experiment with different use cases, and gain practical experience in incorporating state-of-the-art AI technologies into real-world applications.\n",
    "### Table of Contents\n",
    "1. [Setup your Anthropic API key](#setup)\n",
    "2. [Make a simple API call to one of Claude's models](#simple)\n",
    "3. [A few options for using the API](#options)\n",
    "4. [Your assignment](#assignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b669b4-fb42-47cb-af5f-f6f47f2cbf70",
   "metadata": {},
   "source": [
    "## Setup your Anthropic API key<a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31f7f885-9ee2-4810-95ff-9c6f85da456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.10/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# This package is not installed in our Sagemaker image.\n",
    "# Everytime you researt this jupyterlab, you will have to reinstall it.\n",
    "%pip install python-dotenv\n",
    "# Now import the objects we need\n",
    "from dotenv import load_dotenv\n",
    "# Other needed packages to import\n",
    "import os\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30712831-2b1a-46ca-b4f5-c63aea7d8c12",
   "metadata": {},
   "source": [
    "To store your API key for use with the requests package:\n",
    "- Get the key from your account on https://console.anthropic.com. It will look something like: \"\"sk-ant-api03-Iu4 ... U37M\"\n",
    "- Now, open a terminal from the jupyter Launcher\n",
    "    - Use the nano text editor (or any other editor)\n",
    "    - Create a .env file (that is a file with the exact name \".env\" (files that start with '.' are hidden by default\n",
    "    - Add a line that looks like this: ANTHROPIC_API_KEY=\"your_key\"\n",
    "       - Insert your key in double-quotes\n",
    "    - Save the file and exit the text editor. In nano: Save (ctl-o), Exit (ctl-x)\n",
    "\n",
    "<P>\n",
    "Next we will load this key into this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce74efc3-5f13-4486-b4fb-9fae3fe55e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Now you can access the environment variable\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# You can print the key to make sure it is there, but I get nervous when I see a key printed somewhere.... Someone could steal it!\n",
    "#print(anthropic_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fc85cf-7502-4afd-80b2-d7d391a692c0",
   "metadata": {},
   "source": [
    "## Make a simple API call to one of Claude's models<a name=\"simple\"></a>\n",
    "If you want to know more: https://docs.anthropic.com/claude/reference/messages_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38deb48e-c33d-4346-9ed8-b10700de087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API endpoint:\n",
    "url = 'https://api.anthropic.com/v1/messages'\n",
    "# Define the headers\n",
    "headers = {\n",
    "    'x-api-key': anthropic_api_key,\n",
    "    'anthropic-version': '2023-06-01',\n",
    "    'content-type': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa8dba5-94de-49a4-9f66-90be53d04288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229', # Select a model from here: https://docs.anthropic.com/claude/docs/models-overview\n",
    "    'max_tokens': 1024,\n",
    "    'messages': [\n",
    "        {'role': 'user', 'content': 'Write a blog post about large language models.'}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c31299-abcb-4dee-9ca6-51e54f3d6304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Make the API POST request.\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable\n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "# When you execute this cell, you are paying to inference the model. It will deduct money from your account.\n",
    "# Therefore, I usually do anything in this cell other than store the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a43b64-72e8-4872-b655-7e64a59d95fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a draft blog post about large language models:\n",
      "\n",
      "Title: The Rise of Large Language Models and Their Impact\n",
      "\n",
      "In recent years, we've seen the emergence of large language models (LLMs) – extremely capable artificial intelligence systems trained on vast amounts of text data to understand and generate human-like language with remarkable fluency. The names of some of the most prominent LLMs like GPT-3, BERT, and LaMDA have become familiar in both tech and mainstream media.  \n",
      "\n",
      "So what exactly are large language models? At their core, they are machine learning models that use neural networks with billions or even trillions of parameters trained on massive datasets like online books, articles, websites, and other digital text. By ingesting and processing an immense corpus of human-written language, these models develop sophisticated skills for understanding context and meaning, answering questions, writing coherent passages, translating between languages, and more.  \n",
      "\n",
      "The capabilities that LLMs now possess are truly astonishing compared to previous generations of AI language tech. They can engage in multi-turn dialogue, be prompted to write creative fiction and poetry, explain complex topics with clarity and depth, answer follow-up queries while maintaining context and memory, and even generate software code from natural language descriptions. The paragraphs I'm writing now could potentially be the output of an advanced LLM like GPT-3 that can seemingly match human writing quality in many areas.\n",
      "\n",
      "Of course, LLMs remain flawed systems prone to making up facts, amplifying biases from their training data, and sometimes producing nonsensical or undesirable outputs—important limitations we must be aware of. But their emergence is widely seen as a milestone in the pursuit of human-level artificial intelligence. They demonstrate the incredible power that can emerge from statistical pattern recognition over massive datasets, even if we don't yet fully understand how these \"black box\" neural networks arrive at their results internally.  \n",
      "\n",
      "So what are the implications of LLM breakthroughs? In the short term, they are unlocking a wave of new applications powered by advanced natural language processing—everything from smarter chatbots and writing aids to improved tools for analysis, tutoring, text summarization, and semantic search. Major tech companies like Google, Microsoft, and OpenAI are fiercely competing to advance their LLM capabilities and endeavors like predictive text on steroids, automated coding assistants, customized AI tutors, and multilingual communication aids.\n",
      "\n",
      "More broadly, the sophistication of large language models hints at the prospect of artificial general intelligence—AI systems that can match human-level reasoning and language capacities across a wide range of domains. While older symbolic rules-based AI has fallen short, the statistical pattern recognition and language mastery demonstrated by LLMs suggests a new path forward. By ingesting enough training data, AI may ultimately approximate aspects of intelligence through brute computation and probability mapping rather than painstakingly engineered human knowledge. LLMs prove the ability of machines to derive rich, generalized models of reality from the latent patterns underlying vast datasets of human-produced information.  \n",
      "\n",
      "However, we are still likely far away from AGI, or artificial general intelligence matching the full scope of human cognition. Current LLMs remain narrow AI with limitations—they lack true understanding, form incoherent beliefs, struggle to learn and update skills, and can't flexibly apply knowledge to the real world. Their mastery is also constrained to the language/text domain where they were trained. Creating context-aware models that can seamlessly navigate the richness of human experience remains an immense challenge not yet overcome.\n",
      "\n",
      "But the rise of large language models represents a milestone and perhaps an early glimpse at the future potential of artificial intelligence. The ability of machines to closely approximate core facets of human linguistic intelligence—communication, knowledge generation, reasoning, instruction following—evolves rapidly. Even if LLMs are just an early step toward eventual artificial general intelligence, they have already transformed our perspective on what is possible with AI. The era of machines mastering the full depth and flexibility of human language may be approaching more rapidly than previously imagined.\n"
     ]
    }
   ],
   "source": [
    "# Look at the resposne\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "395cf782-805a-4bcc-96fa-83a31bf8d5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'msg_01RwHuHkJyYhDxWG5ZkbfNEs',\n",
       " 'type': 'message',\n",
       " 'role': 'assistant',\n",
       " 'model': 'claude-3-sonnet-20240229',\n",
       " 'stop_sequence': None,\n",
       " 'usage': {'input_tokens': 16, 'output_tokens': 874},\n",
       " 'content': [{'type': 'text',\n",
       "   'text': 'Here is a draft blog post about large language models:\\n\\nTitle: The Rise of Large Language Models and Their Impact\\n\\nIn recent years, we\\'ve seen the emergence of large language models (LLMs) – extremely capable artificial intelligence systems trained on vast amounts of text data to understand and generate human-like language with remarkable fluency. The names of some of the most prominent LLMs like GPT-3, BERT, and LaMDA have become familiar in both tech and mainstream media.  \\n\\nSo what exactly are large language models? At their core, they are machine learning models that use neural networks with billions or even trillions of parameters trained on massive datasets like online books, articles, websites, and other digital text. By ingesting and processing an immense corpus of human-written language, these models develop sophisticated skills for understanding context and meaning, answering questions, writing coherent passages, translating between languages, and more.  \\n\\nThe capabilities that LLMs now possess are truly astonishing compared to previous generations of AI language tech. They can engage in multi-turn dialogue, be prompted to write creative fiction and poetry, explain complex topics with clarity and depth, answer follow-up queries while maintaining context and memory, and even generate software code from natural language descriptions. The paragraphs I\\'m writing now could potentially be the output of an advanced LLM like GPT-3 that can seemingly match human writing quality in many areas.\\n\\nOf course, LLMs remain flawed systems prone to making up facts, amplifying biases from their training data, and sometimes producing nonsensical or undesirable outputs—important limitations we must be aware of. But their emergence is widely seen as a milestone in the pursuit of human-level artificial intelligence. They demonstrate the incredible power that can emerge from statistical pattern recognition over massive datasets, even if we don\\'t yet fully understand how these \"black box\" neural networks arrive at their results internally.  \\n\\nSo what are the implications of LLM breakthroughs? In the short term, they are unlocking a wave of new applications powered by advanced natural language processing—everything from smarter chatbots and writing aids to improved tools for analysis, tutoring, text summarization, and semantic search. Major tech companies like Google, Microsoft, and OpenAI are fiercely competing to advance their LLM capabilities and endeavors like predictive text on steroids, automated coding assistants, customized AI tutors, and multilingual communication aids.\\n\\nMore broadly, the sophistication of large language models hints at the prospect of artificial general intelligence—AI systems that can match human-level reasoning and language capacities across a wide range of domains. While older symbolic rules-based AI has fallen short, the statistical pattern recognition and language mastery demonstrated by LLMs suggests a new path forward. By ingesting enough training data, AI may ultimately approximate aspects of intelligence through brute computation and probability mapping rather than painstakingly engineered human knowledge. LLMs prove the ability of machines to derive rich, generalized models of reality from the latent patterns underlying vast datasets of human-produced information.  \\n\\nHowever, we are still likely far away from AGI, or artificial general intelligence matching the full scope of human cognition. Current LLMs remain narrow AI with limitations—they lack true understanding, form incoherent beliefs, struggle to learn and update skills, and can\\'t flexibly apply knowledge to the real world. Their mastery is also constrained to the language/text domain where they were trained. Creating context-aware models that can seamlessly navigate the richness of human experience remains an immense challenge not yet overcome.\\n\\nBut the rise of large language models represents a milestone and perhaps an early glimpse at the future potential of artificial intelligence. The ability of machines to closely approximate core facets of human linguistic intelligence—communication, knowledge generation, reasoning, instruction following—evolves rapidly. Even if LLMs are just an early step toward eventual artificial general intelligence, they have already transformed our perspective on what is possible with AI. The era of machines mastering the full depth and flexibility of human language may be approaching more rapidly than previously imagined.'}],\n",
       " 'stop_reason': 'end_turn'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look closer at the entire response. Other data is included\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f9c82-19f8-4603-a913-83b436f0dfbc",
   "metadata": {},
   "source": [
    "## A few options for using the API<a name=\"options\"></a>\n",
    "- max_tokens\n",
    "- temperature\n",
    "- Multiple conversational turns\n",
    "- Using the conversation history in multiple API calls (keeping the context of the conversation active)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b87d21-af97-40c5-ac0d-8f5ef627322e",
   "metadata": {},
   "source": [
    "#### max_tokens\n",
    "When using the Anthropic Claude API, the `max_tokens` parameter is an important setting that allows you to control the length of the generated text response. The `max_tokens` parameter specifies the maximum number of tokens (words or word pieces) that the model should generate in the response. This is useful for preventing the model from generating excessively long or open-ended responses, which can help manage the response size and cost when using the API. By adjusting the `max_tokens` value, you can balance the desired level of detail and conciseness in the generated text to best fit the needs of your application. Understanding how to effectively leverage the `max_tokens` parameter is an important consideration when integrating the powerful Claude language model through the REST API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b280fc6-2bbd-417b-8b0c-61c9597b5aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Max tokens\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 100, # short, interrupted response\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"Can you explain Artificial Neural Networks plain English?\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable\n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1530d0b-ae3e-487f-996e-a6c37974b375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'll do my best to explain artificial neural networks in plain English.\n",
      "\n",
      "An artificial neural network is a computing system that is designed to mimic the way the human brain processes information. Just like the brain is made up of interconnected neurons, an artificial neural network is made up of interconnected nodes or \"neurons\" that transmit signals between each other.\n",
      "\n",
      "The neural network is first \"trained\" on a large set of data. During this training process, the connections between the nodes\n",
      "\n",
      "\n",
      "Why the response ended: max_tokens\n",
      "Token usage: {'input_tokens': 17, 'output_tokens': 100}\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)\n",
    "print('\\n\\nWhy the response ended:', response.json()['stop_reason'])\n",
    "print('Token usage:', response.json()['usage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03ff4e2-8311-4888-b256-b27f605ddc95",
   "metadata": {},
   "source": [
    "#### temperature\n",
    "The `temperature` parameter in the Anthropic Claude API is a setting that controls the \"creativity\" or \"randomness\" of the generated text. Temperature is a value between 0 and 1 that affects the model's probability distribution when choosing the next token in the output. \n",
    "\n",
    "A lower temperature (closer to 0) results in more deterministic, logical, and \"safer\" text generation, as the model will tend to choose the most probable next tokens based on the training data. This can be useful for generating text that needs to adhere to specific guidelines or patterns.\n",
    "\n",
    "Conversely, a higher temperature (closer to 1) introduces more randomness and creativity into the text generation process. The model will explore a wider range of possible next tokens, leading to more diverse, unexpected, and imaginative outputs. This can be beneficial for tasks like creative writing, brainstorming, or open-ended exploration.\n",
    "\n",
    "By adjusting the `temperature` parameter, users of the Claude API can control the balance between coherence/safety and creativity/unpredictability in the model's generated text, allowing them to fine-tune the output to best suit their specific application needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b2455c-f55f-4a51-894b-d3f7d81f3e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Temperature (low temperature, less random, more deterministic or conservative)\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 200, \n",
    "    # Low temperature (more deterministic, less random)\n",
    "    'temperature':0,\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"Please tell me a bedtime story.\"},\n",
    "  ]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable    \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35865295-aec5-4237-9eab-d824cff84cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a calming bedtime story for you:\n",
      "\n",
      "The Sleepy Forest\n",
      "\n",
      "Deep in the heart of an ancient forest, there was a small clearing surrounded by towering oak and pine trees. Moonlight filtered through the branches, casting a gentle glow over the mossy ground. \n",
      "\n",
      "A babbling brook ran along one side of the clearing, its soothing sounds like a lullaby. Fireflies danced lazily above the water, their lights blinking on and off in a twinkling rhythm.\n",
      "\n",
      "In the center of the clearing stood a great willow tree, its long branches swaying ever so slightly in the night breeze. Underneath this willow, a bed of soft ferns and wildflowers made the perfect spot for sleepy forest creatures to rest their heads.\n",
      "\n",
      "As the night wore on, the animals of the forest began making their way to the willow's sheltering branches. A family of rabbits hopped\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd883f96-e3be-4a0f-b6ff-16f31d8519f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Temperature (High temperature, more random, less deterministic or less conservative)\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 100, \n",
    "    # High temperature (more random, more creative)\n",
    "    'temperature':1.0,\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"Please tell me a bedtime story.\"},\n",
    "  ]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable        \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "267d66c0-63c0-4a95-94cf-a80151d81be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a calming bedtime story for you:\n",
      "\n",
      "The Sleepy Little Cloud\n",
      "\n",
      "Once upon a time, there was a little cotton ball cloud who loved floating high up in the bright blue sky. His name was Cumulus, and he spent his days happily drifting wherever the warm breezes took him. \n",
      "\n",
      "One evening, as the sun began to set, Cumulus looked around and realized he was all alone up in the darkening sky. \"Where\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc317e-959f-46eb-b8fe-518563b611cc",
   "metadata": {},
   "source": [
    "#### multiple conversation turns\n",
    "When using the Anthropic Claude API, the ability to maintain multiple conversation turns is an important feature. This allows you to provide the model with a conversational context, where each subsequent request builds upon the previous responses. The API supports storing this conversational state, enabling the model to understand and respond to the evolving context. This can be particularly useful for creating more natural, coherent, and contextual interactions between the user and the AI assistant. By leveraging multiple conversation turns, you can create more engaging and informative dialogues that draw upon the model's accumulated knowledge and understanding of the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0c7408b-3e24-4959-8260-c8ad7c6e47ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Multiple conversational turns: https://docs.anthropic.com/claude/reference/messages-examples#multiple-conversational-turns\n",
    "# Define the data\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 200,\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"I have an AI question, are you ready?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Hi, I'm Claude an AI assistant, so I know a lot about it. Please, please ask me anything about AI.\"},\n",
    "  {\"role\": \"user\", \"content\": \"Can you explain Artificial Neural Networks plain English, including an analogy?\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable       \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "691492f3-55f1-409a-9c75-2f359e36f4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I can try to explain artificial neural networks in plain English using an analogy. \n",
      "\n",
      "An artificial neural network is a computing system that is very loosely modeled after the biological neural networks in the human brain. Just like the brain is made up of interconnected neurons that transmit signals, an artificial neural network has interconnected nodes (artificial neurons) that transmit information.\n",
      "\n",
      "Here's an analogy that may help visualize it:\n",
      "\n",
      "Imagine a company that has many offices in different locations. Each office is like a neuron or node in the network. The employees at each office are collectively doing some work and computing something based on the resources and input data they receive.\n",
      "\n",
      "The different offices are connected by roads, which are like the connections or weights between neurons. Just as roads have varying traffic capacities, the connections between neurons have varying strengths that get adjusted during training.\n",
      "\n",
      "When an office receives an input (like a shipment of materials), they process it\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356a54f9-6312-4bab-86a6-7f0f5f3c92b3",
   "metadata": {},
   "source": [
    "#### Using the conversation history in multiple API calls\n",
    "The Anthropic Claude API supports the ability to maintain and utilize conversation history across multiple API calls. By passing the conversation history as part of each subsequent request, the model can reference and build upon the prior context, resulting in more coherent and contextual responses. Leveraging the conversation history is particularly useful for tasks that require an ongoing dialogue, such as open-ended Q&A, task completion, or collaborative ideation. This feature allows you to create more natural and engaging interactions, where the AI assistant can demonstrate an understanding of the discussion and provide relevant and tailored responses based on the evolving conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7df1c1e6-a67b-4eec-afa2-a45589ba3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Create a list to keep the API text responses\n",
    "message_lst = [] #empty list\n",
    "# Define the data\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 200,\n",
    "    'messages': [\n",
    "  {\"role\": \"user\", \"content\": \"Please explain the difference between Artifical Intelligence and Machine Learning.\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200: # All went well\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable           \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "# Keep a history: append the text to the list\n",
    "message_lst.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d87752b-dc9b-4ce9-bb33-32b446007e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry: 1 \n",
      " Text: Artificial Intelligence (AI) and Machine Learning (ML) are closely related but distinct concepts. Here's an explanation of the difference between the two:\n",
      "\n",
      "Artificial Intelligence (AI):\n",
      "AI is a broad field that encompasses the development of intelligent machines capable of performing tasks that would typically require human intelligence. It involves the study of how to make computers and machines mimic human cognitive functions such as learning, problem-solving, reasoning, perception, and language understanding. AI aims to create systems that can perceive their environment, process data, make decisions, and take actions to achieve specific goals.\n",
      "\n",
      "Machine Learning (ML):\n",
      "Machine Learning is a subset of AI and is focused on the development of algorithms and statistical models that enable systems to learn from data and make predictions or decisions without being explicitly programmed. It involves feeding large amounts of data to algorithms, which then learn patterns, relationships, and insights from that data. The algorithms can then use this knowledge to make predictions or decisions on new, \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at our current list of responses\n",
    "for i,r in enumerate(message_lst):\n",
    "    print('Entry:', i+1, '\\n','Text:', r,'\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b0080f0-2a4a-4b10-823e-bd4832146e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The API call was successful.\n"
     ]
    }
   ],
   "source": [
    "# Pass the history back into the assistant with a follow-up instruction.\n",
    "data = {\n",
    "    'model': 'claude-3-sonnet-20240229',\n",
    "    'max_tokens': 200,\n",
    "    'messages': [\n",
    "        {\"role\": \"user\", \"content\": \"Please explain the difference between Artifical Intelligence and Machine Learning.\"},\n",
    "        # Pass in the history\n",
    "        {\"role\": \"assistant\", \"content\": \" \".join(message_lst)}, # Combine all messages into a single string\n",
    "        # Give further instructions\n",
    "        {\"role\": \"user\", \"content\": \"Please reduce this explaination to a single paragraph.\"},\n",
    "]\n",
    "}\n",
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "# Handle the response\n",
    "if response.status_code == 200:\n",
    "    print('The API call was successful.')\n",
    "    # Store the response content into a variable            \n",
    "    generated_text = response.json()['content'][0]['text']\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "# Append to the end of the list\n",
    "message_lst.append(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00654edd-7846-4caf-8437-f4d12f585428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry: 1 \n",
      " Text: Artificial Intelligence (AI) and Machine Learning (ML) are closely related but distinct concepts. Here's an explanation of the difference between the two:\n",
      "\n",
      "Artificial Intelligence (AI):\n",
      "AI is a broad field that encompasses the development of intelligent machines capable of performing tasks that would typically require human intelligence. It involves the study of how to make computers and machines mimic human cognitive functions such as learning, problem-solving, reasoning, perception, and language understanding. AI aims to create systems that can perceive their environment, process data, make decisions, and take actions to achieve specific goals.\n",
      "\n",
      "Machine Learning (ML):\n",
      "Machine Learning is a subset of AI and is focused on the development of algorithms and statistical models that enable systems to learn from data and make predictions or decisions without being explicitly programmed. It involves feeding large amounts of data to algorithms, which then learn patterns, relationships, and insights from that data. The algorithms can then use this knowledge to make predictions or decisions on new, \n",
      "\n",
      "\n",
      "Entry: 2 \n",
      " Text: Artificial Intelligence (AI) is a broad field that aims to create intelligent machines capable of performing tasks that typically require human intelligence, such as learning, problem-solving, reasoning, perception, and language understanding. Machine Learning (ML), on the other hand, is a subset of AI that focuses on developing algorithms and statistical models that enable systems to learn from data and make predictions or decisions without being explicitly programmed. While AI encompasses various approaches and techniques for building intelligent systems, Machine Learning specifically deals with the ability of these systems to automatically improve their performance based on exposure to data. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at our current list of responses\n",
    "for i,r in enumerate(message_lst):\n",
    "    print('Entry:', i+1, '\\n','Text:', r,'\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2cb0d-e29d-4a7c-a143-427b7f09ab3e",
   "metadata": {},
   "source": [
    "## Your assignment:<a name=\"assignment\"></a>\n",
    "Using the examples above, create 3 unique API calls (different than my examples) using a combination of parameters and techniques. Print your responses just as I have done above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46160187-bac0-4a3c-971f-f22ba4166862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4da9dd-37e4-4829-9dbe-2615b0e0859b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
