{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf86a47-b70a-498a-8dbc-de917d47fa84",
   "metadata": {},
   "source": [
    "### Retrival Augmentented Generation Day 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7347c523-adac-43c8-b651-acc6281afd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain_cohere -q\n",
    "%pip install spacy -q\n",
    "%pip install psycopg2 -q\n",
    "%pip install python-dotenv -q\n",
    "#ignore error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d4086-c974-496a-99e1-2d5584e0755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you need to run this in a terminal window\n",
    "# python -m spacy download en_core_web_md\n",
    "# now restart your kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a4fed-79a7-4616-96b5-813c6f5bcc9a",
   "metadata": {},
   "source": [
    "Standard imports for the libraires we will be using in this notebook.  Try to keep your imports in the first cell so this can this code can more easliy be converted into a python program later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1513731f-ab9f-4e74-9249-e8ff08dfd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "import traceback\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.chat_models import BedrockChat\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "import dbconnection\n",
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Create the AWS client for the Bedrock runtime with boto3\n",
    "aws_client = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec844-3eee-4ce4-993d-d72ab9dd8560",
   "metadata": {},
   "source": [
    "#### Lets define functions that will use various embedding models so we can generate vector embeddings\n",
    "Spacey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1b6024-dda4-4dd3-836d-5830b472d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spacy_vector_embedding(text):\n",
    "    embedder = SpacyEmbeddings(model_name=\"en_core_web_md\")\n",
    "    query_embedding = embedder.embed_query(text)\n",
    "\n",
    "    return(np.array(query_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35157a12-af69-4d79-8a9f-d7229eef4bec",
   "metadata": {},
   "source": [
    "Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0667bf3-01ef-4493-8cbc-744413c0d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send in an array size of one and only return the 0th element\n",
    "def generate_cohere_vector_embedding(text_data):\n",
    "    input_type = \"clustering\"\n",
    "    truncate = \"NONE\" # optional\n",
    "    model_id = \"cohere.embed-english-v3\" # or \"cohere.embed-multilingual-v3\"\n",
    "    \n",
    "    # Create the JSON payload for the request\n",
    "    json_params = {\n",
    "            'texts': [text_data],\n",
    "            'truncate': truncate, \n",
    "            \"input_type\": input_type\n",
    "        }\n",
    "    json_body = json.dumps(json_params)\n",
    "    params = {'body': json_body, 'modelId': model_id,}\n",
    "    \n",
    "    # Invoke the model and print the response\n",
    "    result = aws_client.invoke_model(**params)\n",
    "    response = json.loads(result['body'].read().decode())\n",
    "    return(np.array(response['embeddings'][0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0f33d-429d-4636-9082-d7bbb9850790",
   "metadata": {},
   "source": [
    "Amazon Titan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5794765f-0b32-451e-a145-6a7b4ce785e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a dense vector using Amazon Titan with LangChain\n",
    "def generate_titan_vector_embedding(text):\n",
    "    #create an Amazon Titan Text Embeddings client\n",
    "    embeddings_client = BedrockEmbeddings(region_name=\"us-west-2\") \n",
    "\n",
    "    #Invoke the model\n",
    "    embedding = embeddings_client.embed_query(text)\n",
    "    return(np.array(embedding))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f08b3826-e751-4f03-b564-e2eb2d3ff00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a dense vector using Amazon Titan without using a np.array as a return value\n",
    "def generate_vector_embedding(text):\n",
    "    #create an Amazon Titan Text Embeddings client\n",
    "    embeddings_client = BedrockEmbeddings(region_name=\"us-west-2\") \n",
    "\n",
    "    #Invoke the model\n",
    "    embedding = embeddings_client.embed_query(text)\n",
    "    #Note pgvector does not want a np.array as out manual method\n",
    "    return(embedding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff40e7e-c880-4dd1-b7ad-70f8a12efe2a",
   "metadata": {},
   "source": [
    "This is the mathmatical formula to calcuate cosine similarity between 2 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e8367a7-c786-41fc-ad05-d53b5633d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6763ad27-f4b8-4f6a-8200-d067332ea4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_value(value):\n",
    "    value_str = str(value)\n",
    "    cleaned_value = ''.join(char for char in value_str if char.isalnum() or char.isspace())\n",
    "    return cleaned_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14383a5-eec2-40e7-9c61-ccadb437d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_string_size(x, max_chars=2048):\n",
    "    # Check if the input is a string\n",
    "    if isinstance(x, str):\n",
    "        return x[:max_chars]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7c74692-d25d-48ae-8fde-04ba53188a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_values(list_stuff: list, num_items: int) -> None:\n",
    "    i=0\n",
    "    for item in list_stuff:\n",
    "        i=i+1\n",
    "        if i>num_items:\n",
    "            return None\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d11db83-cffa-4ebc-8f41-5392bb92cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean abstract text\n",
    "#df = pd.read_csv('data/latest_research_articles.csv')\n",
    "#df['abstract'] = df['abstract'].apply(clean_value)\n",
    "\n",
    "#df\n",
    "dft = pd.read_pickle('data/embedded_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea212b3-6d8f-441b-9671-35a9c1346474",
   "metadata": {},
   "source": [
    "### Advanced Retrieval Techniques\n",
    "#### HyDE\n",
    "A technique that optimizes semantic matching requires better semantic context.  What if we generated a document from the query that better match our stored document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33147a2d-fc4c-4b20-83c5-34ee32426933",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieval from embedded sources\n",
    "#Now that we have a dataframe with embedded content of interest, we can use semantic similarity to retrieve the right data to feed to an LLM\n",
    "\n",
    "# Given the following query let's generate context that more closely matches the embedded data\n",
    "query = \"What is the latest research for broken ribs in children\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c85c16-1ef1-424d-9167-09166e696e49",
   "metadata": {},
   "source": [
    "#### Calling the LLM with Python\n",
    "Before we embed the vector with the query let's transform the query into a fake article.  This article will likely have a larger semantic overlap than the original smaller question. Using Bedrock we will now call Anthropic Claude Sonnet to generate a fictitous article.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f48e81ca-c394-49ab-b5f0-cbaab5f7aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate HyDE context\n",
    "\n",
    "def generate_hyde_response(query_phrase):\n",
    "    model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "    # Each model will named parameters which will likely be different depending on the providor\n",
    "    model_kwargs =  { \n",
    "        \"max_tokens\": 400, # This is the maximum output tokens you want the model to use\n",
    "        \"temperature\": 1,  # Temperature controls the randomness and creativity of the generated text.\n",
    "        \"top_k\": 250,      # Top-k parameter determines the number of highest probability next word choices the model should conside\n",
    "        \"top_p\": 0.9,      # Top-p sampling considers the cumulative probability distribution of the next word choices and sets a probability threshold\n",
    "        \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "    }\n",
    "    # LangChain tooling\n",
    "    model = BedrockChat(\n",
    "        client=aws_client,\n",
    "        model_id=model_id,\n",
    "        model_kwargs=model_kwargs,\n",
    "    )\n",
    "    \n",
    "    human_prompt = \"Given the following question \\n {query} can you please generate a paragraph of text that answers the question. Be sure to use scientific \\\n",
    "                    medical terminology. Please just include the paragraph in your response.\"\n",
    "    # Uses the messaging method which is required for all Claude 3 calls\n",
    "    messages = [\n",
    "        (\"system\", \"You are a helpful assistant\"),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    "    try:\n",
    "        prompt = ChatPromptTemplate.from_messages(messages)\n",
    "        # LangChain at work\n",
    "        chain = prompt | model | StrOutputParser()\n",
    "\n",
    "\n",
    "        # Send the message content to Claude using Bedrock and get the response\n",
    "        start_time = time.time()  # Start timing\n",
    "        # Call Bedrock\n",
    "        response = chain.invoke({\"query\": query_phrase})\n",
    "        end_time = time.time()  # End timing\n",
    "        print(\"Claude call took :\", end_time - start_time)  # Calculate execution time\n",
    "\n",
    "        return(response)\n",
    "    except Exception as e:\n",
    "        exc_type, exc_value, exc_traceback = traceback.sys.exc_info()\n",
    "        line_number = exc_traceback.tb_lineno\n",
    "        print(f\"Errort: {exc_type}{exc_value}{exc_traceback} on {line_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53f80486-0d15-4500-88f2-c4eb93550ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude call took : 3.290161609649658\n",
      "The management of rib fractures in pediatric patients has undergone significant advancements in recent years. Clinicians now employ a multidisciplinary approach, combining pharmacological interventions with innovative therapeutic modalities. Analgesic regimens, encompassing opioid and non-opioid medications, are tailored to alleviate acute pain and facilitate respiratory function. Concurrently, emerging techniques like ultrasound-guided regional anesthesia and cryotherapy have demonstrated promising results in pain management and reducing the risk of complications. Furthermore, researchers are exploring the potential benefits of early mobilization and targeted physiotherapy protocols, aimed at enhancing recovery and minimizing long-term respiratory impairments.\n"
     ]
    }
   ],
   "source": [
    "print(generate_hyde_response(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0949d-dad2-4fa3-b6cc-a11c5a61fc09",
   "metadata": {},
   "source": [
    "#### Titan Embeddings - SAME No HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd1325dd-7635-4017-871b-c12bfa26faaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few articles that may match your interest:\n",
      "Abtract: 'High sensitivity methods for automated rib fracture detection in pediatric radiographs' with a cosine match of: 0.46759500523692665\n",
      "Abtract: 'Magnetic resonance imaging based finite element modelling of the proximal femur: a short-term in vivo precision study' with a cosine match of: 0.23057253235100217\n",
      "Abtract: 'On the crashworthiness analysis of bio-inspired DNA tubes' with a cosine match of: 0.21674978237483608\n",
      "Abtract: 'Reproduction of forearm rotation dynamic using intensity-based biplane 2D–3D registration matching method' with a cosine match of: 0.19907903320363604\n",
      "Abtract: 'Propagation of extended fractures by local nucleation and rapid transverse expansion of crack-front distortion' with a cosine match of: 0.19056102046718387\n"
     ]
    }
   ],
   "source": [
    "# Let's search our records for a good semantic search\n",
    "query_vector = generate_titan_vector_embedding(query)\n",
    "\n",
    "results = []\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in dft.iterrows():\n",
    "    # Extract the value from the specified column\n",
    "    article_embedding = row['embedded_abstract']\n",
    "    results.append((index, cosine_similarity(article_embedding, query_vector)))\n",
    "    #print (index, value)\n",
    "\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "i = 0\n",
    "# Print the sorted data\n",
    "print(\"Here are a few articles that may match your interest:\")\n",
    "for item in results:\n",
    "    article_title = dft.iloc[item[0]]['title']\n",
    "    print(f\"Abtract: '{article_title}' with a cosine match of: {item[1]}\")\n",
    "    i=i+1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effb9abd-19f9-4e88-8b16-91fc57a440da",
   "metadata": {},
   "source": [
    "Now let's compare our cosine scores with HyDE . . ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b02d48ef-2c13-4f4f-9389-76b60de4ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude call took : 6.0228471755981445\n",
      "Here are a few articles that may match your interest:\n",
      "Abtract: 'High sensitivity methods for automated rib fracture detection in pediatric radiographs' with a cosine match of: 0.6292173704538236\n",
      "Abtract: 'AI co-pilot bronchoscope robot' with a cosine match of: 0.32338228689168846\n",
      "Abtract: 'Non-invasive biomarkers for detecting progression toward hypovolemic cardiovascular instability in a lower body negative pressure model' with a cosine match of: 0.31326814424948946\n",
      "Abtract: 'Magnetic resonance imaging based finite element modelling of the proximal femur: a short-term in vivo precision study' with a cosine match of: 0.26150022736172723\n",
      "Abtract: 'Development and validation of a semi-automated and unsupervised method for femur segmentation from CT' with a cosine match of: 0.2510235206731928\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's search our records for a good semantic search\n",
    "query_vector = generate_titan_vector_embedding(generate_hyde_response(query))\n",
    "# This is a tuple of the article index and the cosine similarity score\n",
    "results = []\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in dft.iterrows():\n",
    "    # Extract the value from the specified column\n",
    "    article_embedding = row['embedded_abstract']\n",
    "    results.append((index, cosine_similarity(article_embedding, query_vector)))\n",
    "    #print (index, value)\n",
    "\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "i = 0\n",
    "# Print the sorted data\n",
    "print(\"Here are a few articles that may match your interest:\")\n",
    "for item in results:\n",
    "    # Use the index from the Original dataframe to extract values of interest\n",
    "    article_title = dft.iloc[item[0]]['title']\n",
    "    print(f\"Abtract: '{article_title}' with a cosine match of: {item[1]}\")\n",
    "    i=i+1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db1008-1a93-4fca-9210-484fddeace0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0b6c4e8-e7f1-40a0-b34a-84e5d67a86e5",
   "metadata": {},
   "source": [
    "#### Differentiating the retrievals and ranking\n",
    " How can we evaluate if the cosine similarities are different enough?  Thresholds aren't consistent enough.  What about Z-Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05f073f8-9e1d-4222-9e68-dc5ea4800b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_zscores(cosine_scores):\n",
    "    zscores = []\n",
    "    # Calculate the mean of the sample points\n",
    "    mean = np.mean(cosine_scores)\n",
    "    # Calculate the standard deviation of the sample points\n",
    "    std_deviation = np.std(cosine_scores, ddof=1)  # ddof=1 for sample standard deviation\n",
    "    # Calculate the z-scores for each sample point\n",
    "    z_scores = [(x - mean) / std_deviation for x in cosine_scores]\n",
    "\n",
    "    return z_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a62de-6ba7-4374-9b4a-3083c10b61db",
   "metadata": {},
   "source": [
    "Let's review our distribution of cosine scores and evaluate a threshold for selection.  We will review z-score and see how that compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1322753b-eefc-472d-874a-a71c10633981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top few cosine-scores\n",
      "0.6292173704538236\n",
      "0.32338228689168846\n",
      "0.31326814424948946\n",
      "0.26150022736172723\n",
      "0.2510235206731928\n",
      "The top few Z-scores\n",
      "12.467139857935173\n",
      "5.885293812988393\n",
      "5.667628367375577\n",
      "4.553536239506188\n",
      "4.32806808955148\n"
     ]
    }
   ],
   "source": [
    "# grab the cosine_scores from the results tuple\n",
    "cosine_scores = [item[1] for item in results]\n",
    "print(\"The top few cosine-scores\")\n",
    "print_top_values(cosine_scores,5)\n",
    "z_scores = calculate_zscores(cosine_scores)\n",
    "# Let's print the top 5 z-scores\n",
    "print(\"The top few Z-scores\")\n",
    "print_top_values(z_scores, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c2e78-2b8f-4baa-a124-fc4d5888b552",
   "metadata": {},
   "source": [
    "#### Sample values for cosine similarity I sampled for another project I used RAG on"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae67d734-4276-4cef-805f-427e8c23d83e",
   "metadata": {},
   "source": [
    "<img src=\"zscore-dist.jpg\" alt=\"Sample Z-Score Distributions\" width=\"300\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caeb3d38-7af9-4ca7-a778-76f6f498cb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: 'High sensitivity methods for automated rib fracture detection in pediatric radiographs' with a cosine match of: 0.6292173704538236 and Z-score of: 12.467139857935173\n",
      "Grabbed the top 1 scores\n"
     ]
    }
   ],
   "source": [
    "# Using our new technique we will concat all relvant results and prepare to send that as context to our LLM\n",
    "articles = \"\"\n",
    "i=0\n",
    "j=0\n",
    "first_z_score = z_scores[0]\n",
    "for item in results:\n",
    "    # Use the index from the Original dataframe to extract values of interest\n",
    "    article_title = dft.iloc[item[0]]['title']\n",
    "    abstract = dft.iloc[item[0]]['abstract']\n",
    "    # If the highest Z score is 2x this record then likey not as significant\n",
    "    if(first_z_score/2)<z_scores[i]:\n",
    "        print(f\"Abstract: '{article_title}' with a cosine match of: {item[1]} and Z-score of: {z_scores[i]}\")\n",
    "        articles = articles + \" \" + abstract\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "print(f\"Grabbed the top {j} scores\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc64a11d-5eb8-417b-9f3c-b288bae676b9",
   "metadata": {},
   "source": [
    "#### Generation\n",
    "Now lets define a function that will call the LLM with the right prompt to generate a summary of the retrieved context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f268e1a0-5ac3-4f96-b838-a816980344e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's take the records that are greater that 1/2 the top Z-score and send those to the LLM for an answer\n",
    "def best_answer(data, question):\n",
    "    model_id = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "    model_kwargs =  { \n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0.0,\n",
    "        \"top_k\": 250,\n",
    "        \"top_p\": 0.9,\n",
    "        \"stop_sequences\": [\"\\n\\nHuman\"],\n",
    "    }\n",
    "\n",
    "    model = BedrockChat(\n",
    "        client=aws_client,\n",
    "        model_id=model_id,\n",
    "        model_kwargs=model_kwargs,\n",
    "    )\n",
    "\n",
    "    human_prompt = \"You are to answer the question using the data in the following information.  Do not make up your answer, only use \\\n",
    "                    supporting data from the article, If you don't have enough data simply respond, I don't have enough information to answer that question. \\\n",
    "                    given the following article data {data} can you please give a concise answer to the following question. {question}\"\n",
    "    messages = [\n",
    "        (\"system\", \"You are a helpful assistant that can answer quesitons based on news articles you have been given.\"),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    "    try:\n",
    "        prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "        chain = prompt | model | StrOutputParser()\n",
    "\n",
    "        # Chain Invoke\n",
    "        \n",
    "    \n",
    "        # Send the message content to Claude using Bedrock and get the response\n",
    "        start_time = time.time()  # Start timing\n",
    "        # Call Bedrock\n",
    "        response = chain.invoke({\"data\": data,\"question\": question})\n",
    "        end_time = time.time()  # End timing\n",
    "        #print(\"Claude call took :\", end_time - start_time)  # Calculate execution time\n",
    "\n",
    "        return(response)\n",
    "    except Exception as e:\n",
    "        exc_type, exc_value, exc_traceback = traceback.sys.exc_info()\n",
    "        line_number = exc_traceback.tb_lineno\n",
    "\n",
    "        return f\"ERROR generating good answer: {exc_type}{exc_value}{exc_traceback} on {line_number}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "472a37eb-70a1-4059-ac56-4a17a6322db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the best answer I could find about  What is the latest research for broken ribs in children\n",
      "Based on the information provided in the article, the latest research focuses on improving the detection and localization of rib fractures in pediatric chest radiographs using computer vision and machine learning techniques. Specifically:\n",
      "\n",
      "- The research implemented convolutional neural network (CNN) architectures like RetinaNet and YOLOv5, along with an \"avalanche decision\" scheme to dynamically adjust detection thresholds, to increase the sensitivity (recall) in detecting rib fractures.\n",
      "\n",
      "- Multiple image preprocessing techniques and model ensembling were used to further enhance detection performance.\n",
      "\n",
      "- Using a dataset of 1,109 pediatric chest radiographs manually labeled by radiologists, the best performing model achieved an F2 score of 0.725, approaching the expert inter-reader performance of 0.732.\n",
      "\n",
      "- The goal was to develop methods that can identify all rib fractures to aid radiologists in interpreting pediatric chest radiographs, as rib fractures are highly indicative of non-accidental trauma in young children and can be challenging to detect.\n",
      "\n",
      "In summary, the latest research focuses on applying advanced computer vision and machine learning models to improve the sensitivity of detecting rib fractures in children's chest X-rays.\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is the best answer I could find about \", query)\n",
    "print(best_answer(articles, query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1a661e-9dfc-420c-a7ac-6d18ed3adbcd",
   "metadata": {},
   "source": [
    "#### RAG is rad\n",
    "Let's explore the power of RAG with another example.  Using a larger document with chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2c8b2df-f7ce-4942-b267-97e488f29d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your large text document\n",
    "with open(\"data/staff-report.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Create a text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,  # Adjust the chunk size as needed\n",
    "    chunk_overlap=512,  # Adjust the overlap between chunks as needed\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "# create a dataframe with new chunk raw text\n",
    "chunk_df = pd.DataFrame({'raw_text': chunks})\n",
    "\n",
    "chunk_df['text_embed'] = chunk_df['raw_text'].apply(generate_titan_vector_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e50d5ca1-f710-4e0e-8312-a147f4378e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top few cosine-scores\n",
      "0.37564064545805465\n",
      "0.3544211509728883\n",
      "0.32852842656319053\n",
      "0.32438156860757617\n",
      "0.31285842398605307\n",
      "The top few Z-scores\n",
      "1.731866991010253\n",
      "1.3917218260436985\n",
      "0.9766655191214498\n",
      "0.9101920371828787\n",
      "0.7254778381259019\n",
      "Using chunk with a cosine match of: 0.37564064545805465 and Z-score of: 1.731866991010253\n",
      "Using chunk with a cosine match of: 0.3544211509728883 and Z-score of: 1.3917218260436985\n",
      "Using chunk with a cosine match of: 0.32852842656319053 and Z-score of: 0.9766655191214498\n",
      "Using chunk with a cosine match of: 0.32438156860757617 and Z-score of: 0.9101920371828787\n",
      "Grabbed the top 4 scores\n",
      "Here is the best answer I could find about  What is the city recommending?\n",
      "Based on the information provided, the city is recommending to authorize the replacement of ActiFlo mixer gearboxes as part of the Water Treatment Plant major facility maintenance. The recommendation states that this item qualifies as a sole source purchase under criteria C, as Philadelphia Mixing Solutions, LLC is the only supplier of the necessary equipment, and MISCOwater is the only authorized company by Philadelphia Mixing Solutions to sell parts and provide service in the regional area including San Luis Obispo.\n"
     ]
    }
   ],
   "source": [
    "# Let's search our records for a good semantic search\n",
    "#query = \"What is the city replacing at the water treatment plant and why?\"\n",
    "query = \"What is the city recommending?\"\n",
    "#query = \"What will it cost to replace the mixer gearbox?\"\n",
    "\n",
    "query_vector = generate_titan_vector_embedding(query)\n",
    "# This is a tuple of the article index and the cosine similarity score\n",
    "results = []\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in chunk_df.iterrows():\n",
    "    # Extract the value from the specified column\n",
    "    article_embedding = row['text_embed']\n",
    "    results.append((index, cosine_similarity(article_embedding, query_vector)))\n",
    "    #print (index, cosine_similarity(article_embedding, query_vector))\n",
    "\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "cosine_scores = [item[1] for item in results]\n",
    "z_scores = calculate_zscores(cosine_scores)\n",
    "\n",
    "\n",
    "print(\"The top few cosine-scores\")\n",
    "print_top_values(cosine_scores,5)\n",
    "# Let's print the top 5 z-scores\n",
    "print(\"The top few Z-scores\")\n",
    "print_top_values(z_scores, 5)\n",
    "\n",
    "#save the articles that were a good match\n",
    "articles = \"\"\n",
    "i=0\n",
    "j=0\n",
    "first_z_score = z_scores[0]\n",
    "for item in results:\n",
    "    # Use the index from the Original dataframe to extract values of interest\n",
    "    chunk_txt = chunk_df.iloc[item[0]]['raw_text']\n",
    "    # If the highest Z score is 2x this record then likey not as significant\n",
    "    if(first_z_score/2)<z_scores[i]:\n",
    "        print(f\"Using chunk with a cosine match of: {item[1]} and Z-score of: {z_scores[i]}\")\n",
    "        articles = articles + \" \" + chunk_txt\n",
    "        j=j+1\n",
    "    i=i+1\n",
    "print(f\"Grabbed the top {j} scores\")  \n",
    "print(\"Here is the best answer I could find about \", query)\n",
    "print(best_answer(articles, query))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8c21e-55bd-4fbe-ba19-ac36beb6938b",
   "metadata": {},
   "source": [
    "### Vector Database for Larger Datasets\n",
    "For our first example we used a local dataframe to store the contents of our raw text and embeddings, then manually calculated similarity between embeddings.  There are other tools that are better suited for larger datasets with embeddings. They are generally called vector databases.  We will explore pgvector running on a Postgresql database engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6460fbcf-1129-4eec-88ba-c6f5abd5bb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My public IP address is: 52.27.224.182\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "\n",
    "ip = get('https://api.ipify.org').content.decode('utf8')\n",
    "print('My public IP address is: {}'.format(ip))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c91e402b-c8d5-43ec-af35-849c40529366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in your username so yoru database entry will be unique to you\n",
    "#MY_USERNAME = \"dkraker@calpoly.edu\"\n",
    "MY_USERNAME = \"YOUR USERNAME HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0e149-5e0e-41e5-bba5-7d9d2f91df37",
   "metadata": {},
   "source": [
    "Let's define a function that will put data into our vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32415403-8b26-460b-9128-9a67b05b4740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_record_into_db(table_name, record, conn):\n",
    "\n",
    "    # Dynamically generates and executes an INSERT SQL statement for PostgreSQL, handling\n",
    "    # special data types like datetime objects and arrays directly.\n",
    "    \n",
    "    # Args:\n",
    "    # - table_name (str): The name of the table into which the record will be inserted.\n",
    "    # - data (dict): A dictionary representing the record to be inserted, where keys are column names\n",
    "    #                  and values can include native PostgreSQL types like datetime and arrays.\n",
    "    # - conn (psycopg2.connection): A psycopg2 connection object.\n",
    "    \n",
    "    # Generate column names and placeholders\n",
    "    columns = ', '.join(record.keys())\n",
    "    placeholders = ', '.join(['%s'] * len(record))  # PostgreSQL uses %s as placeholder\n",
    "\n",
    "    # Create the INSERT INTO statement\n",
    "    sql = f'INSERT INTO {table_name} ({columns}) VALUES ({placeholders})'\n",
    "    #print(\"columns=\", columns)\n",
    "    #print(\"placeholders=\", placeholders)\n",
    "    #print(sql)\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        cur.execute(sql, tuple(record.values()))\n",
    "        conn.commit()\n",
    "        print(\"Record inserted successfully.\")\n",
    "    except psycopg2.Error as e:\n",
    "        print(\"An error occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e6ee978-95da-4158-a760-0c8658f136c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n",
      "Record inserted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load your large text document\n",
    "with open(\"data/staff-report.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Create a text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1024,  # Adjust the chunk size as needed\n",
    "    chunk_overlap=512,  # Adjust the overlap between chunks as needed\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "chunks = text_splitter.split_text(text)\n",
    "\n",
    "conn = dbconnection.open_connection_to_db()\n",
    "try:\n",
    "    # create a dataframe with new chunk raw text\n",
    "    for chunk in chunks:\n",
    "        data_record = {}\n",
    "        v_embed = generate_vector_embedding(chunk)\n",
    "        data_record[\"username\"] = MY_USERNAME\n",
    "        data_record[\"textattribute1\"] = chunk\n",
    "        data_record[\"textattribute2\"] = \"\"\n",
    "        data_record[\"textattribute3\"] = \"\"\n",
    "        data_record[\"textattribute4\"] = \"\"\n",
    "        data_record[\"textattribute5\"] = \"\"\n",
    "        data_record[\"textembedding1\"] = v_embed\n",
    "        insert_record_into_db(\"rag\", data_record, conn)        \n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47fc908-102b-4a6d-8e1a-7cc3e294d999",
   "metadata": {},
   "source": [
    "Now let's use the database as a way to find the best match. Notice the 2 different commented SQL syntax differences.  We can easily compute Euclidean distance as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1b8f77b-af42-40f8-88a6-7ce83ff14fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_similarity_search_pgvector(question, embedded_text, conn):\n",
    "    # Cosine similarity\n",
    "    #1-(textembedding1 <=> ('{embedded_text}')) as cosine_similar  \\\n",
    "    # Euclidean distance\n",
    "    #textembedding1 <-> ('{embedded_text}') as euclidean_distance  \\\n",
    "    sql = f\"SELECT textattribute1, textattribute2, textattribute3, textattribute4, textattribute5, \\\n",
    "                1-(textembedding1 <=> ('{embedded_text}')) as cosine_similar  \\\n",
    "                FROM public.rag \\\n",
    "                WHERE username = '{MY_USERNAME}' \\\n",
    "                ORDER BY cosine_similar DESC \\\n",
    "                LIMIT 50\"\n",
    "    #print(sql)\n",
    "    cosine_scores = []\n",
    "    try:\n",
    "        article_text = \"\"\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(sql)\n",
    "        rows = cur.fetchall()\n",
    "\n",
    "        # grab the cosine scores so we can compute Z score for narrow article selection\n",
    "        # need all scores so we can calc Z\n",
    "        for row in rows:\n",
    "            #print(row[5])\n",
    "            cosine_scores.append(row[5])\n",
    "            \n",
    "        z_scores = calculate_zscores(cosine_scores)\n",
    "        answer = \"Unknown\"\n",
    "        article_text = \"\"\n",
    "        zscore_index = 0\n",
    "        first_z_score = z_scores[0]\n",
    "        for row in rows:\n",
    "            if(first_z_score/2)<z_scores[zscore_index]:\n",
    "                print(f\"Using chunk with a cosine match of: {row[5]} and Z-score of: {z_scores[zscore_index]}\")\n",
    "                article_text = article_text + row[0] + \"\\n\"\n",
    "            zscore_index += 1\n",
    "        #print(article_text)\n",
    "        answer = best_answer(article_text, question)\n",
    "        #Close cursor and connection\n",
    "        cur.close()\n",
    "        return answer\n",
    "        \n",
    "    except psycopg2.Error as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2445f9b6-fe86-4a1c-8b38-236c3e88b278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using chunk with a cosine match of: 19.49773609028711 and Z-score of: 1.20770147938811\n",
      "Using chunk with a cosine match of: 19.398213318025984 and Z-score of: 1.1365966074246054\n",
      "Using chunk with a cosine match of: 19.363000316324946 and Z-score of: 1.1114383856376002\n",
      "Using chunk with a cosine match of: 19.06951395040491 and Z-score of: 0.9017546117870814\n",
      "Using chunk with a cosine match of: 18.780663403380984 and Z-score of: 0.6953829372839252\n",
      "Using chunk with a cosine match of: 18.658562853913413 and Z-score of: 0.6081471847087676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"According to the information provided, the total estimated cost to replace the mixer gearboxes for the Actiflo ballasted flocculation system at the City's Water Treatment Plant is $500,322. Specifically, it states that the bid estimate from the sole source vendor MISCOwater for the replacement parts is $416,935, and with a 20% contingency added, the total project cost would be $500,322.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#query = \"What is the city recommending?\"\n",
    "query = \"What will it cost to replace the mixer gearbox?\"\n",
    "\n",
    "query_vector = generate_vector_embedding(query)\n",
    "\n",
    "conn = dbconnection.open_connection_to_db()\n",
    "\n",
    "run_similarity_search_pgvector(query, query_vector, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8562e-d5b3-4a54-b1fc-4448c33608a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_my_data(conn):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # SQL statement to delete rows where username is 'bob'\n",
    "        sql = f\"SELECT textattribute1, textattribute2, textattribute3, textattribute4, textattribute5 FROM public.rag WHERE username = '{MY_USERNAME}'\"\n",
    "    \n",
    "        # Execute the SQL statement\n",
    "        cur.execute(sql)\n",
    "        rows = cur.fetchall()\n",
    "\n",
    "        # grab the cosine scores so we can compute Z score for narrow article selection\n",
    "        for row in rows:\n",
    "            print(row[0], row[1], row[2], row[3], row[4])\n",
    "    \n",
    "        \n",
    "\n",
    "        \n",
    "    except psycopg2.Error as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5021db-398f-437b-855a-d4c8ad4d3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = dbconnection.open_connection_to_db()\n",
    "view_my_data(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74a487bd-e287-4fd4-b9b3-c19efbb7c1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purge_my_data(conn):\n",
    "    \n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        # SQL statement to delete rows where username is 'bob'\n",
    "        sql = f\"DELETE FROM public.rag WHERE username = '{MY_USERNAME}'\"\n",
    "    \n",
    "        # Execute the SQL statement\n",
    "        cur.execute(sql)\n",
    "    \n",
    "        # Commit the changes to the database\n",
    "        conn.commit()\n",
    "    \n",
    "        # Get the number of affected rows\n",
    "        deleted_rows = cur.rowcount\n",
    "        print(f\"{deleted_rows} row(s) deleted.\")\n",
    "\n",
    "        \n",
    "    except psycopg2.Error as e:\n",
    "            print(\"An error occurred:\", e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d53dba01-eb07-43fa-a617-8de799704356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 row(s) deleted.\n"
     ]
    }
   ],
   "source": [
    "conn = dbconnection.open_connection_to_db()\n",
    "purge_my_data(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef427a2-b526-4c34-9202-b2a4cbe0970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = dbconnection.open_connection_to_db()\n",
    "try:\n",
    "    data_record = {}\n",
    "    data_record[\"username\"] = MY_USERNAME\n",
    "    data_record[\"textattribute1\"] = \"TEST1\"\n",
    "    data_record[\"textattribute2\"] = \"TEST2\"\n",
    "    data_record[\"textattribute3\"] = \"TEST3\"\n",
    "    data_record[\"textattribute4\"] = \"TEST4\"\n",
    "    data_record[\"textattribute5\"] = \"TEST5\"\n",
    "    data_record[\"textembedding1\"] = generate_vector_embedding(\"TEST1\")\n",
    "    data_record[\"textembedding2\"] = generate_vector_embedding(\"TEST2\")\n",
    "    data_record[\"textembedding3\"] = generate_vector_embedding(\"TEST3\")\n",
    "    data_record[\"textembedding4\"] = generate_vector_embedding(\"TEST4\")\n",
    "    \n",
    "    insert_record_into_db(\"rag\", data_record, conn)              \n",
    "    #print(data_record)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "finally:\n",
    "    if conn:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077766d-8d7b-47a1-a816-6c9b2906ea1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
