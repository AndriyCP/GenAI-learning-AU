{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edf86a47-b70a-498a-8dbc-de917d47fa84",
   "metadata": {},
   "source": [
    "### Retrival Augmentented Generation\n",
    "\n",
    "#### Vector embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7347c523-adac-43c8-b651-acc6281afd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "botocore 1.34.51 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.2.1 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\n",
      "transformers 4.31.0 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_cohere -q\n",
    "%pip install spacy -q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d4086-c974-496a-99e1-2d5584e0755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now you need to run this in a terminal window\n",
    "# python -m spacy download en_core_web_md\n",
    "# now restart your kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a4fed-79a7-4616-96b5-813c6f5bcc9a",
   "metadata": {},
   "source": [
    "Standard imports for the libraires we will be using in this notebook.  Try to keep your imports in the first cell so this can this code can more easliy be converted into a python program later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1513731f-ab9f-4e74-9249-e8ff08dfd433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import pyarrow\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "# Create the AWS client for the Bedrock runtime with boto3\n",
    "aws_client = boto3.client(service_name=\"bedrock-runtime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceec844-3eee-4ce4-993d-d72ab9dd8560",
   "metadata": {},
   "source": [
    "#### Lets define functions that will use various embedding models so we can generate vector embeddings\n",
    "Spacey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd1b6024-dda4-4dd3-836d-5830b472d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spacy_vector_embedding(text):\n",
    "    embedder = SpacyEmbeddings(model_name=\"en_core_web_md\")\n",
    "    query_embedding = embedder.embed_query(text)\n",
    "\n",
    "    return(np.array(query_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf40345-ad82-4d53-bfa6-19360a03c4de",
   "metadata": {},
   "source": [
    "Huggingface Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb9c64d-f1a7-4123-b197-05d485553761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_huggingface_vector_embedding(text):\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"bert-base-uncased\")\n",
    "    embedded_texts = embeddings.embed_query(text_data)\n",
    "    return(embedded_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35157a12-af69-4d79-8a9f-d7229eef4bec",
   "metadata": {},
   "source": [
    "Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0667bf3-01ef-4493-8cbc-744413c0d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send in an array size of one and only return the 0th element\n",
    "def generate_cohere_vector_embedding(text_data):\n",
    "    input_type = \"clustering\"\n",
    "    truncate = \"NONE\" # optional\n",
    "    model_id = \"cohere.embed-english-v3\" # or \"cohere.embed-multilingual-v3\"\n",
    "    \n",
    "    # Create the JSON payload for the request\n",
    "    json_params = {\n",
    "            'texts': [text_data],\n",
    "            'truncate': truncate, \n",
    "            \"input_type\": input_type\n",
    "        }\n",
    "    json_body = json.dumps(json_params)\n",
    "    params = {'body': json_body, 'modelId': model_id,}\n",
    "    \n",
    "    # Invoke the model and print the response\n",
    "    result = aws_client.invoke_model(**params)\n",
    "    response = json.loads(result['body'].read().decode())\n",
    "    return(np.array(response['embeddings'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e8367a7-c786-41fc-ad05-d53b5633d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    return similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0f33d-429d-4636-9082-d7bbb9850790",
   "metadata": {},
   "source": [
    "Amazon Titan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5794765f-0b32-451e-a145-6a7b4ce785e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's generate a dense vector using Amazon Titan with LangChain\n",
    "def generate_titan_vector_embedding(text):\n",
    "    #create an Amazon Titan Text Embeddings client\n",
    "    embeddings_client = BedrockEmbeddings(region_name=\"us-west-2\") \n",
    "\n",
    "    #Invoke the model\n",
    "    embedding = embeddings_client.embed_query(text)\n",
    "    return(np.array(embedding))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4047ec8c-4391-4504-b444-783e00f64f08",
   "metadata": {},
   "source": [
    "Now let's generate vectors for simple words and compare how we can compute cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75541e21-0738-46c6-87f2-ca48e26d7862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25       -0.91015625  0.55078125  0.59375     0.5546875 ]\n"
     ]
    }
   ],
   "source": [
    "#Titan\n",
    "king_vector = generate_titan_vector_embedding(\"King\")\n",
    "queen_vector = generate_titan_vector_embedding(\"Queen\")\n",
    "man_vector = generate_titan_vector_embedding(\"man\")\n",
    "woman_vector = generate_titan_vector_embedding(\"woman\")\n",
    "print(king_vector[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1403336c-54d9-47ca-b6aa-71e33d3ff78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity distance between Titan King - Queen: 0.6676\n",
      "Cosine Similarity of Titan King to Queen: 0.6291\n"
     ]
    }
   ],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Titan King - Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity of Titan King to Queen: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15ce1c26-96bd-4ad0-9363-43652357245d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02391052 -0.02467346  0.02523804 -0.04049683 -0.06323242]\n"
     ]
    }
   ],
   "source": [
    "# Input cohere for embedding \n",
    "king_vector = generate_cohere_vector_embedding('King')\n",
    "queen_vector = generate_cohere_vector_embedding(\"Queen\")\n",
    "man_vector = generate_cohere_vector_embedding(\"man\")\n",
    "woman_vector = generate_cohere_vector_embedding(\"woman\")\n",
    "print(king_vector[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32463138-8d0c-4029-a3db-47df1b4aedc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity distance between Cohere King - Queen: 0.7226\n",
      "Cosine Similarity of Cohere King to Queen: 0.7328\n"
     ]
    }
   ],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Cohere King - Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity of Cohere King to Queen: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa44abe0-4283-4ec9-8a00-182dad13a06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.19343001 -4.19689989  4.81750011 -0.72863001  2.31769991]\n"
     ]
    }
   ],
   "source": [
    "#Spacy\n",
    "king_vector = generate_spacy_vector_embedding(\"King\")\n",
    "queen_vector = generate_spacy_vector_embedding(\"Queen\")\n",
    "man_vector = generate_spacy_vector_embedding(\"man\")\n",
    "woman_vector = generate_spacy_vector_embedding(\"woman\")\n",
    "print(king_vector[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0a9fc52-a659-4270-bab1-370fb67e64a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity distance between Spacey King - Queen: 0.6892\n",
      "Cosine Similarity of Spacey King to Queen: 0.6593\n"
     ]
    }
   ],
   "source": [
    "calculated_queen_vector = king_vector - man_vector + woman_vector\n",
    "\n",
    "similarity = cosine_similarity(calculated_queen_vector, queen_vector)\n",
    "print(f\"Cosine Similarity distance between Spacey King - Queen: {similarity:.4f}\")\n",
    "\n",
    "similarity = cosine_similarity(king_vector, queen_vector)\n",
    "print(f\"Cosine Similarity of Spacey King to Queen: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1110c8bd-2a42-4541-bb17-36dcfd7b2890",
   "metadata": {},
   "source": [
    "Let's examine other phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21063601-c5c2-449d-b6ca-6b1b6aee6c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of cat to book using Titan: 0.3514\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_titan_vector_embedding(\"cat\"), generate_titan_vector_embedding(\"book\"))\n",
    "print(f\"Cosine Similarity of cat to book using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de7a6da4-8667-4eaf-beeb-764883ac0031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of cat to book using Cohere: 0.5575\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_cohere_vector_embedding(\"cat\"), generate_cohere_vector_embedding(\"book\"))\n",
    "print(f\"Cosine Similarity of cat to book using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebbe9ee1-905c-425b-b44e-81fc1fa5ec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of cat to book using Spacey: 0.0696\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(generate_spacy_vector_embedding(\"cat\"), generate_spacy_vector_embedding(\"book\"))\n",
    "print(f\"Cosine Similarity of cat to book using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420fad29-9e38-4434-a200-e8fd414003c9",
   "metadata": {},
   "source": [
    "Now let's look at a larger sentences and see how larger models with more complexity handle the same task\n",
    "Here are 2 sentences that semantically similar but use different words and phrasing.\n",
    "\n",
    "1. The majestic, towering skyscrapers, their gleaming windows reflecting the golden rays of the setting sun, stood as a testament to human ingenuity and the \n",
    " indomitable spirit of progress, while the bustling streets below teemed with life as people from all walks of life hurried to their destinations, their faces \n",
    " a mix of determination and weariness, yet each individual contributing to the vibrant tapestry of the city's existence.\n",
    "\n",
    "2. The awe-inspiring, colossal high-rises, their polished glass facades mirroring the warm, amber glow of the fading daylight, served as a powerful symbol of human\n",
    " innovation and the unyielding drive for advancement, as the lively thoroughfares beneath pulsed with energy, filled with individuals from diverse backgrounds rushing\n",
    " to their intended locations, their expressions an amalgamation of resolve and fatigue, yet all playing a vital role in the dynamic, intricate mosaic that shaped the \n",
    " city's vibrant identity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2f5da62-2cbd-4d40-b02b-57b89bba9cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Spacey: 0.9776\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"The majestic, towering skyscrapers, their gleaming windows reflecting the golden rays of the setting sun, stood as a testament to human ingenuity and the indomitable spirit of progress, while the bustling streets below teemed with life as people from all walks of life hurried to their destinations, their faces a mix of determination and weariness, yet each individual contributing to the vibrant tapestry of the city's existence.\"\n",
    "sentence2 = \"The awe-inspiring, colossal high-rises, their polished glass facades mirroring the warm, amber glow of the fading daylight, served as a powerful symbol of human innovation and the unyielding drive for advancement, as the lively thoroughfares beneath pulsed with energy, filled with individuals from diverse backgrounds rushing to their intended locations, their expressions an amalgamation of resolve and fatigue, yet all playing a vital role in the dynamic, intricate mosaic that shaped the city's vibrant identity.\"\n",
    "similarity = cosine_similarity(generate_spacy_vector_embedding(sentence1), generate_spacy_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Spacey: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37fdd6ba-7828-482b-9636-908ebeba22cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Titan: 0.8726\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"The majestic, towering skyscrapers, their gleaming windows reflecting the golden rays of the setting sun, stood as a testament to human ingenuity and the indomitable spirit of progress, while the bustling streets below teemed with life as people from all walks of life hurried to their destinations, their faces a mix of determination and weariness, yet each individual contributing to the vibrant tapestry of the city's existence.\"\n",
    "sentence2 = \"The awe-inspiring, colossal high-rises, their polished glass facades mirroring the warm, amber glow of the fading daylight, served as a powerful symbol of human innovation and the unyielding drive for advancement, as the lively thoroughfares beneath pulsed with energy, filled with individuals from diverse backgrounds rushing to their intended locations, their expressions an amalgamation of resolve and fatigue, yet all playing a vital role in the dynamic, intricate mosaic that shaped the city's vibrant identity.\"\n",
    "similarity = cosine_similarity(generate_titan_vector_embedding(sentence1), generate_titan_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Titan: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bce6b2e-5ee0-405e-aef2-d8635133663f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity of S1 to S2 using Cohere: 0.8156\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"The majestic, towering skyscrapers, their gleaming windows reflecting the golden rays of the setting sun, stood as a testament to human ingenuity and the indomitable spirit of progress, while the bustling streets below teemed with life as people from all walks of life hurried to their destinations, their faces a mix of determination and weariness, yet each individual contributing to the vibrant tapestry of the city's existence.\"\n",
    "sentence2 = \"The awe-inspiring, colossal high-rises, their polished glass facades mirroring the warm, amber glow of the fading daylight, served as a powerful symbol of human innovation and the unyielding drive for advancement, as the lively thoroughfares beneath pulsed with energy, filled with individuals from diverse backgrounds rushing to their intended locations, their expressions an amalgamation of resolve and fatigue, yet all playing a vital role in the dynamic, intricate mosaic that shaped the city's vibrant identity.\"\n",
    "similarity = cosine_similarity(generate_cohere_vector_embedding(sentence1), generate_cohere_vector_embedding(sentence2))\n",
    "print(f\"Cosine Similarity of S1 to S2 using Cohere: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3a31a-406d-417a-b752-f3c3afd0a66f",
   "metadata": {},
   "source": [
    "#### Right model for the right job\n",
    "Bigger models aren't necessarily more capable for all tasks.  On simple sentences Spacey results show it to be the best model for this task.  Let's switch to a more complex task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7230a6-86c4-4950-a793-6bae2bb4925d",
   "metadata": {},
   "source": [
    "#### Persistance of embeddings for later retrieval\n",
    " In order to do semantic search and retrieve relevant content we need to store that content for later use.  We can store the embedding in several different persistence technologies.  To start simply let's store the data in memory using pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6763ad27-f4b8-4f6a-8200-d067332ea4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_value(value):\n",
    "    value_str = str(value)\n",
    "    cleaned_value = ''.join(char for char in value_str if char.isalnum() or char.isspace())\n",
    "    return cleaned_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b14383a5-eec2-40e7-9c61-ccadb437d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_string_size(x, max_chars=2048):\n",
    "    # Check if the input is a string\n",
    "    if isinstance(x, str):\n",
    "        return x[:max_chars]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d11db83-cffa-4ebc-8f41-5392bb92cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean abstract text\n",
    "df = pd.read_csv('data/latest_research_articles.csv')\n",
    "df['abstract'] = df['abstract'].apply(clean_value)\n",
    "# for cohere we need to limit the string size to 2048\n",
    "df['abstract'] = df['abstract'].apply(limit_string_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99dfb897-a1aa-4a82-8ac0-3825eefb1afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Lets save the dataframe in 4 separate so we can parallalize the embedding\n",
    "df1, df2, df3, df4 = np.array_split(df, 4)\n",
    "df1.to_pickle('data/non-embedded_df1.pkl')\n",
    "df2.to_pickle('data/non-embedded_df2.pkl')\n",
    "df3.to_pickle('data/non-embedded_df3.pkl')\n",
    "df4.to_pickle('data/non-embedded_df4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce2815ed-ffe2-469a-96aa-b73e9d642a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings using Titan\n",
    "# Add a new column 'embedded_abstract' by applying the function to an existing column\n",
    "df['embedded_abstract'] = df['abstract'].apply(generate_cohere_vector_embedding)\n",
    "\n",
    "# This step takes a while so I did it for you and saved the output as pickle\n",
    "#dft = pd.read_pickle('data/embedded_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "35dd7ad6-0484-460b-883b-2867d66cd819",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('data/cohere_embedded.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1516c06b-233a-491d-81cb-063013875f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also generated Spacey embedding so we can compare\n",
    "df1 = pd.read_pickle('data/embedded_spacey_df1.pkl')\n",
    "df2 = pd.read_pickle('data/embedded_spacey_df2.pkl')\n",
    "df3 = pd.read_pickle('data/embedded_spacey_df3.pkl')\n",
    "df4 = pd.read_pickle('data/embedded_spacey_df4.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5b82fb5-4cc9-43b4-ba86-202bfbcd39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes that have been embedded then combine\n",
    "dfs = pd.concat([df1, df2, df3, df4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08975b47-f547-4930-a7e4-42876c00e7e9",
   "metadata": {},
   "source": [
    "### Retrieval from embedded sources\n",
    "Now that we have a dataframe with embedded content of interest, we can use semantic similarity to retrieve the right data to feed to an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89b25889-1d6a-4c2f-bd19-5d117cff23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's setup a query that a used might ask\n",
    "query = \"What is the latest research for broken ribs in children\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f13dbb-b9b9-4063-9d5a-1c229a83d0e3",
   "metadata": {},
   "source": [
    "#### Spacey Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8d92007-07f0-45d0-a267-93f83f23beb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few articles that may match your interest:\n",
      "Abtract: 'In situ evidence of magnetic reconnection in turbulent plasma' with a cosine match of: 0.8912633568632342\n",
      "Abtract: 'Nodal s± pairing symmetry in an iron-based superconductor with only hole pockets' with a cosine match of: 0.8862041687900892\n",
      "Abtract: 'A finite-temperature phase transition for disordered weakly interacting bosons in one dimension' with a cosine match of: 0.8836382547782047\n",
      "Abtract: 'Enhanced production of multi-strange hadrons in high-multiplicity proton–proton collisions' with a cosine match of: 0.8823746488702473\n",
      "Abtract: 'Destabilization of hidden order in URu2Si2 under magnetic field and pressure' with a cosine match of: 0.8814906267428417\n"
     ]
    }
   ],
   "source": [
    "# Let's search our records for a good semantic search\n",
    "#query_vector = generate_titan_vector_embedding(query)\n",
    "query_vector = generate_spacy_vector_embedding(query)\n",
    "\n",
    "results = []\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in dfs.iterrows():\n",
    "    # Extract the value from the specified column\n",
    "    article_embedding = row['embedded_abstract']\n",
    "    results.append((index, cosine_similarity(article_embedding, query_vector)))\n",
    "    #print (index, value)\n",
    "\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "i = 0\n",
    "# Print the sorted data\n",
    "print(\"Here are a few articles that may match your interest:\")\n",
    "for item in results:\n",
    "    article_title = dfs.iloc[item[0]]['title']\n",
    "    print(f\"Abtract: '{article_title}' with a cosine match of: {item[1]}\")\n",
    "    i=i+1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0949d-dad2-4fa3-b6cc-a11c5a61fc09",
   "metadata": {},
   "source": [
    "#### Titan Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b02d48ef-2c13-4f4f-9389-76b60de4ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few articles that may match your interest:\n",
      "Abtract: 'High sensitivity methods for automated rib fracture detection in pediatric radiographs' with a cosine match of: 0.46759500523692665\n",
      "Abtract: 'Magnetic resonance imaging based finite element modelling of the proximal femur: a short-term in vivo precision study' with a cosine match of: 0.23057253235100217\n",
      "Abtract: 'On the crashworthiness analysis of bio-inspired DNA tubes' with a cosine match of: 0.21674978237483608\n",
      "Abtract: 'Reproduction of forearm rotation dynamic using intensity-based biplane 2D–3D registration matching method' with a cosine match of: 0.19907903320363604\n",
      "Abtract: 'Propagation of extended fractures by local nucleation and rapid transverse expansion of crack-front distortion' with a cosine match of: 0.19056102046718387\n"
     ]
    }
   ],
   "source": [
    "# Let's search our records for a good semantic search\n",
    "query_vector = generate_titan_vector_embedding(query)\n",
    "\n",
    "results = []\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in dft.iterrows():\n",
    "    # Extract the value from the specified column\n",
    "    article_embedding = row['embedded_abstract']\n",
    "    results.append((index, cosine_similarity(article_embedding, query_vector)))\n",
    "    #print (index, value)\n",
    "\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "i = 0\n",
    "# Print the sorted data\n",
    "print(\"Here are a few articles that may match your interest:\")\n",
    "for item in results:\n",
    "    article_title = dft.iloc[item[0]]['title']\n",
    "    print(f\"Abtract: '{article_title}' with a cosine match of: {item[1]}\")\n",
    "    i=i+1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858166f7-846f-411b-8cd6-7f147ae62128",
   "metadata": {},
   "source": [
    "#### Cohere Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23ca5cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few articles that may match your interest:\n",
      "Abtract: 'High sensitivity methods for automated rib fracture detection in pediatric radiographs' with a cosine match of: 0.5573478086622601\n",
      "Abtract: 'Magnetic resonance imaging based finite element modelling of the proximal femur: a short-term in vivo precision study' with a cosine match of: 0.37145634366738145\n",
      "Abtract: 'Non-invasive biomarkers for detecting progression toward hypovolemic cardiovascular instability in a lower body negative pressure model' with a cosine match of: 0.3522809783290321\n",
      "Abtract: 'A machine learning-based multiscale model to predict bone formation in scaffolds' with a cosine match of: 0.35033143216672435\n",
      "Abtract: 'Application of machine learning algorithms for accurate determination of bilirubin level on in vitro engineered tissue phantom images' with a cosine match of: 0.3347026832383261\n"
     ]
    }
   ],
   "source": [
    "# Let's search our records for a good semantic search\n",
    "query_vector = generate_cohere_vector_embedding(query)\n",
    "\n",
    "results = []\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Extract the value from the specified column\n",
    "    article_embedding = row['embedded_abstract']\n",
    "    results.append((index, cosine_similarity(article_embedding, query_vector)))\n",
    "    #print (index, value)\n",
    "\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "i = 0\n",
    "# Print the sorted data\n",
    "print(\"Here are a few articles that may match your interest:\")\n",
    "for item in results:\n",
    "    article_title = df.iloc[item[0]]['title']\n",
    "    print(f\"Abtract: '{article_title}' with a cosine match of: {item[1]}\")\n",
    "    i=i+1\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b6c4e8-e7f1-40a0-b34a-84e5d67a86e5",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    " For this task Titan performed much better in this scenario.  There are many models out there, before you begin to solve a problem with these new models that are changing daily take some time to test out a few before you land on a solution set.\n",
    " \n",
    " Here is a list of benchmarks for large embedded text models, most models nw have benchmarks with model performance.\n",
    "\n",
    " [Massive Text Embedding Benchmark](https://huggingface.co/spaces/mteb/leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d0a65-12f1-45a2-96d2-0ad8462715be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6fae8-b188-4bc4-a379-44f0adb23d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
